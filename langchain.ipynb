{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9f6920-bbf2-4330-aa98-a6b3a9cb5f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5ef7d4-ab8d-4a8d-a707-35572f37c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader, ArxivLoader, WikipediaLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cc588-55f2-4265-9db7-6ab052529362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need more context-aware chunking that respects language boundaries, RecursiveCharacterTextSplitter is the better choice. \n",
    "# If you just need simple, fixed-size slices of text regardless of where the splits occur, then CharacterTextSplitter will do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6632981-f16e-4e6b-af19-4d1b12d19e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"C:/Users/Hp/Desktop/datasets/langchain/docs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9550bebf-0481-4d17-99be-3c1cd763bda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x173d3095510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e710c0b-a68b-4a62-9fb1-cee983dcaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a50e31-ba6d-41ea-a9fb-265cb09f1ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='LangChain is an innovative framework designed to streamline the development of applications that leverage large language models (LLMs). It offers developers a structured way to integrate, orchestrate, and chain together various LLM functionalities into comprehensive workflows. By abstracting away many of the complexities inherent in managing language models, LangChain enables rapid prototyping and deployment of applications ranging from chatbots and virtual assistants to sophisticated text analysis tools.\\n\\nOne of the core strengths of LangChain is its modular design. Developers can build \"chains\" of operations where the output of one component becomes the input for the next, enabling complex, multi-step processing pipelines. This approach not only improves efficiency but also allows for greater customization and control over how language models are used within an application. Additionally, LangChain supports integration with external data sources and APIs, which further enhances its versatility in real-world applications.\\n\\nMoreover, LangChain fosters an ecosystem where research and development in natural language processing can be translated into practical, user-friendly solutions. As more organizations and developers adopt the framework, it continues to evolve, incorporating cutting-edge techniques and best practices from the AI community. In essence, LangChain represents a significant step forward in making advanced language model capabilities more accessible and functional for a wide array of applications.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9adfd08-0523-464c-93a6-c6b136ce5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(\"C:/Users/Hp/Desktop/Resume_Rajita_Mishra.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abeca1e2-722b-44ad-b139-0dc18ae22b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2023-09-28T22:45:34+05:30', 'title': 'Microsoft Word - Rajita_Mishra_Resume.docx', 'author': 'Yash Nayak', 'moddate': '2023-09-28T22:45:34+05:30', 'source': 'C:/Users/Hp/Desktop/Resume_Rajita_Mishra.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Rajita  Mishra:  Product  Manage r-I, Product Analytics  at Samsung -SRIB  \\n     EX-Paytm  Payments  Bank  |EX-EXL Service|  MTech -Intelligent  System  and Robotics  \\n       \\nAddress:   Bangalore, Whitefield, 560066                                             LinkedIn : Rajita  Mishra \\nPhone:  9717339383  \\nE-mail:  rajita18mishra@gmail.com  \\n \\n  Summary  \\nExperienced data -informed product manager with approximately 6 years of expertise in FinTech and AdTech. Prior background \\nin analytics provides a solid foundation in data analysis and proficiency in tools lik e Tableau/Power BI and SQL for extracting \\ninsights to drive data -driven decisions .  \\nSkills:  \\n \\nCoding:  SQL,  PL-SQL,  HQL,  DAX  for Power  BI. \\nTools/DB: Balsamiq /Figma,  SSRS,  HIVE, Redshift , Athena, ORACLE,  MS-SQL Server,  Quick sight , Domo, Power  BI, Tableau,  Excel.  \\nSkills:  Preparation  of BRD,  PRD,  Scrum  Planning,  Roadmap,  Product  Analysis  and Dashboarding,  Product  Management . \\n    \\n   Work  History  \\nMay 2022  - Current   Product Analytics Lead – Reporting & Insights  \\n Samsung  Research: Samsung Ads  (Ad-tech)  \\n \\n• Spearheaded the  deployment of a real -time dashboard s, on Power -BI, Domo and Quicksight , \\nproficient  in ETL , data visualization  and decision  making via data driven insights . \\n• Lead reporting charter for Samsung’s ACR  tech , and initiative for successful POC. Decipher ed data \\nfor product decisions, by identifying top market contributo rs to sign  up for ACR tech on  \\nSamsung CTV’s  \\n• Analyzed ACR Data to understand viewing behavior  and usage such as programs, movies, ads, \\ngaming , content,  and OTT apps in real -time . Optimized ACR algorithms to improve ACR data \\ncapture accuracy by 50%  \\n• Owned product roadmap to integrate this data to build control groups,  to improve campaign \\ntargeting , improving user engagement metrics  (reach, time spent)  by 2%  \\n• Developed and executed a comprehensive plan to address critical data challenges in Tizen OS \\nLicensed TVs reporting , resulting in a streamlined reporting process and revised data integrity by \\n30%  \\n• Revamped & increased adoption rate of Samsung’s DSP performance campaign reporting feature \\nfrom ~20% to ~60%  \\n \\n Jan 2021 - May 2022             Senior Data Analyst - Ad Tech  \\n                                                      Zapr Media Labs ( Acquired by Samsung Research, Samsung Ads) , Bangalore  \\n \\n• Automated Report ing Ta sks, Improved resource utilization by cutting down operational \\nreporting task from 80% to 30%  \\n• Managed client  communications  & delivered reports worth Rs.10 Lakh MOM  \\n• Developed data -driven recommendations to improve media plans, leveraging TV viewership \\nmedia metrics (Reach, Time spent, TVR , App Users ) \\n• Tracked performance of Media TV campaigns  (Budget of Rs. ~3 -4 Cr) /E-commerce Brands (KIA, \\nSebaMed,  Liberty  Insurance, Flipkart, Swiggy)  \\n• Expertise’s in  devising post campaign analysis and attribution -based  reporting , to regulate end \\nof funnel metrics'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2023-09-28T22:45:34+05:30', 'title': 'Microsoft Word - Rajita_Mishra_Resume.docx', 'author': 'Yash Nayak', 'moddate': '2023-09-28T22:45:34+05:30', 'source': 'C:/Users/Hp/Desktop/Resume_Rajita_Mishra.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='May 2020 - Dec 2020  Senior  Business  Analyst - Product  team  (Payout  & UPI) \\nPaytm  Payments  Bank , Noida  \\n \\n• Conducted in -depth funnel analyses on the Paytm Payment Bank app to examine user behaviors \\nat each stage of journey  \\n• Investigated the most frequently used or abandoned app features at different \\nfunnel stages, result ed in a 10% improvement in feature prioritization  \\n• Investigated product tre nds & key metrics to identify opportunities, for Product sales,  \\nperformance  and improving  efficiency.  KAM resource utilization was up by ~5% . \\n• Analyzed user behavior through A/B testing  to enhance engagement and retention \\nmetrics  \\n• Created PRD for Enterprise Payment solutions for Large Merchants solving Funding and  \\nDisbursal  needs  (Bills,  Salaries,  Wallet  Gratification,  Gift Coupons)  \\n \\nJan 2019 – May 2019  Business  Analyst  – BFSI  Analytics/Reporting  Team  \\nEXL, Noida  \\n \\n• Specialized in providing strategic insights through the implementation of  interactive dashboards  \\non tableau , increasing operational efficiency by 50%  \\n• Develop & deliver Fraud Analytics MVP, adding $300K to P&L, along wi th an additional $750K of \\nprofit over the next 3 y ears \\n• Ironed out revenue reporting process by implementing automated data analysis via SSRS, refined \\ndata accuracy by 95% and reduced reporting time by 50%, enabling data -driven decision -making  \\n \\n \\nMar 2018 - Jan 2019   Business  Analyst  – Project  Management  \\n         TwinSpark  Technology  and Consulting  LLP, Noida   \\n•  Owned the creation and preparation of innovative wireframes for proposed products, ensuring a \\nuser  centric approach  and solving customer needs  \\n•  Managed  the entire  life cycle  from  inception  to launch  for a suite  of products , worked cross -\\nfunctionally with engineering and customer success to achieve product goal  \\n•  Designed , modelled,  and organized  complex  data  on SQL Serv er to curate dashboards  on Power  BI, \\nfor IDP generating revenue  over $ 50,000  \\n•  Prepar ed product requirement document (PRD), wrote u ser stories  and acceptance criteria’s for \\nfeatures of an enterprise system  \\n•  Well versed with agile methodologies, scrum planning and have extensively worked on Jira  \\n \\n \\n   Education  \\n \\nMay 2017 – May 2018         MTech:  Intelligence  System  & Robotics  \\n        Gautam  Buddha  University  - Greater  Noida,  UP  \\nMay 2013 – May 2017        BTech:  Electrical,  Electronics  and Communications  Engineering  \\n      Gautam  Buddha  University  - Greater  Noida')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891acfc8-39f3-4949-91d2-b1c99b1abfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_loader = WebBaseLoader(web_path = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0100e76-749d-41b1-819b-829d0ba3a1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n\\n\\n\\nNlp\\nLanguage-Model\\nAgent\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2024 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e82522-68ab-4dd9-8ac0-fcdec14c4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "web_loader = WebBaseLoader(web_path = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\"),\n",
    "                          bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                              class_=(\"post-title\",\"post-header\")\n",
    "                          ))\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462d45d7-cb41-47d1-bdb0-33425f676eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97173041-3cb4-4c84-8419-ed5807316fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = ArxivLoader(query=\"1605.08386\",load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30666455-fe44-449d-be62-b3147b653b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2016-05-26', 'Title': 'Heat-bath random walks with Markov bases', 'Authors': 'Caprice Stanley, Tobias Windisch', 'Summary': 'Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.'}, page_content='arXiv:1605.08386v1  [math.CO]  26 May 2016\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nAbstract. Graphs on lattice points are studied whose edges come from a ﬁnite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on ﬁbers of a\\nﬁxed integer matrix can be bounded from above by a constant. We then study the mixing\\nbehaviour of heat-bath random walks on these graphs. We also state explicit conditions\\non the set of moves so that the heat-bath random walk, a generalization of the Glauber\\ndynamics, is an expander in ﬁxed dimension.\\nContents\\n1.\\nIntroduction\\n1\\n2.\\nGraphs and statistics\\n3\\n3.\\nBounds on the diameter\\n4\\n4.\\nHeat-bath random walks\\n8\\n5.\\nAugmenting Markov bases\\n14\\nReferences\\n19\\n1. Introduction\\nA ﬁber graph is a graph on the ﬁnitely many lattice points F ⊂Zd of a polytope where\\ntwo lattice points are connected by an edge if their diﬀerence lies in a ﬁnite set of allowed\\nmoves M ⊂Zd. The implicit structure of these graphs makes them a useful tool to explore\\nthe set of lattice points randomly: At the current lattice point u ∈F, an element m ∈±M\\nis sampled and the random walk moves along m if u + m ∈F and stays at u otherwise.\\nThe corresponding Markov chain is irreducible if the underlying ﬁber graph is connected and\\nthe set M is called a Markov basis for F in this case. This paper investigates the heat-bath\\nversion of this random walk: At the current lattice point u ∈F, we sample m ∈M and move\\nto a random element in the integer ray (u + Z · m) ∩F. The authors of [6] discovered that\\nthis random walk can be seen as a discrete version of the hit-and-run algorithm [15, 26, 16]\\nthat has been used frequently to sample from all the points of a polytope – not only from its\\nlattice points. The popularity of the continuous version of the hit-and-run algorithm has not\\nspread to its discrete analog, and not much is known about its mixing behaviour. One reason\\nis that it is already challenging to guarantee that all points in the underlying set F can be\\nDate: September 12, 2018.\\n2010 Mathematics Subject Classiﬁcation. Primary: 05C81, Secondary: 37A25, 11P21.\\nKey words and phrases. Heat-bath random walks, sampling, lattice points, Markov bases.\\n1\\n2\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nreached by a random walk that uses moves from M, whereas for the continuous version, a\\nrandom sampling from the unit sphere suﬃces. However, in many situations where a Markov\\nbasis is known, the heat-bath random walk is evidently fast. For instance, it was shown in [3]\\nthat the heat-bath random walk on contingency tables mixes rapidly when the number of\\ncolumns is ﬁxed. To work around the connectedness issue, a discrete hit-and-run algorithm\\nwas introduced in [1] for arbitrary ﬁnite sets F ⊂Zd. At each step in this random walk, a\\nsubordinate and unrestricted random walk starts at the current lattice point u ∈F and uses\\nthe unit vectors to collect a set of proposals S ⊂Zd. The random walk then moves from u\\nto a random point in S ∩F.\\nRandom walks of the heat-bath type, such as the one presented above, have been studied\\nrecently in [8] in a more general context. In this paper, we explore the mixing behaviour of\\nheat-bath random walks on the lattice points of polytopes with Markov bases. Throughout,\\nwe assume that a Markov basis has been found already and refer to the relevant literature\\nfor their computation [24, 25, 11, 17, 10, 21]. We call the underlying graph of the heat-bath\\nrandom walk a compressed ﬁber graph (Deﬁnition 2.5) and determine in Section 3 bounds on\\nits graph-diameter. We prove that for any A ∈Zm×d with kerZ(A)∩Nd = {0}, the diameter of\\ncompressed ﬁber graphs on {u ∈Nd : Au = b} that use a ﬁxed Markov bases M ⊂kerZ(A) is\\nbounded from above by a constant as b varies (Theorem 3.15). In contrast, we show that the\\ndiameter of conventional ﬁber graphs grow linearly under a dilation of the underlying polytope\\n(Remark 3.9). This gives rise to slow mixing results for conventional ﬁber walks as observed\\nin [27]. In Section 4, we study in more detail the combinatorial and analytical structure\\nof the transition matrices of heat-bath random walks on lattice points and prove upper and\\nlower bounds on their second largest eigenvalues. We also discuss how the distribution on the\\nmoves M aﬀects the speed of convergence (Example 4.21). Theorem 5.8 establishes with the\\ncanonical path approach from [23] an upper bound on the second largest eigenvalue when the\\nMarkov basis is augmenting (Deﬁnition 5.1) and the stationary distribution is uniform. From\\nthat, we conclude fast mixing results for random walks on lattice points in ﬁxed dimension.\\nAcknowledgements. CS was partially supported by the US National Science Foundation\\n(DMS 0954865). TW gratefully acknowledges the support received from the German National\\nAcademic Foundation.\\nConventions and Notation. The natural numbers are N := {0, 1, 2, . . .} and for any N ∈N,\\nN>N := {n ∈N : n > N} and N≥N := {N} ∪N>N. For n ∈N>0, let [n] := {1, . . . , n}. Let\\nM ⊂Qd be a ﬁnite set, then Z·M := {λm : m ∈M, λ ∈Z} and NM is the aﬃne semigroup\\nin Zd generated by M. For an integer matrix A ∈Zm×d with columns a1, . . . , ad ∈Zm,\\nwe write NA := N{a1, . . . , ad}. A graph is always undirected and can have multiple loops.\\nThe distance of two nodes u, v which are contained in the same connected component of a\\ngraph G, i.e. the number of edges in a shortest path between u and v in G, is denoted by\\ndistG(u, v). We set distG(u, v) := ∞if u and v are disconnected. A mass function on a ﬁnite\\nset Ωis a map f : Ω→[0, 1] such that P\\nω∈Ωf(ω) = 1. A mass function f on Ωis positive\\nif f(ω) > 0 for all ω ∈Ω. A set F ⊂Zd is normal if it there exists a polytope P ⊂Qd such\\nthat P ∩Zd = F.\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n3\\n2. Graphs and statistics\\nWe ﬁrst introduce the statistical framework in which this paper lives and recall important\\naspects of the interplay between graphs and statistics. A random walk on a graph G = (V, E)\\nis a map H : V × V →[0, 1] such that for all v ∈V , P\\nu∈V H(v, u) = 1 and such that\\nH(v, u) = 0 if {v, u} ̸∈E. When there is no ambiguity, we represent a random walk as an\\n|V | × |V |-matrix, for example when it is clear how the elements of V are ordered. Fix a\\nrandom walk H on G. Then H is irreducible if for all v, u ∈V there exists t ∈N such that\\nHt(v, u) > 0. The random walk H is reversible if there exists a mass function µ : V →[0, 1]\\nsuch that µ(u) · H(u, v) = µ(v) · H(v, u) for all u, v ∈V and symmetric if H is a symmetric\\nmap. A mass function π : V →[0, 1] is a stationary distribution of H if π ◦H = π. For\\nsymmetric random walks, the uniform distribution on V is always a stationary distribution.\\nIf |V | = n, then we denote the eigenvalues of H by 1 = λ1(H) ≥λ2(H) ≥· · · ≥λn(H) ≥−1\\nand we write λ(H) := max{λ2(H), −λn(H)} for the second largest eigenvalue modulus of H.\\nAny irreducible random walk has a unique stationary distribution [14, Corollary 1.17] and\\nλ(H) ∈[0, 1] measures the convergence rate: the smaller λ(H), the faster the convergence.\\nThe aim of this paper is to study random walks on lattice points that use a set of moves.\\nTypically, this is achieved by constructing a graph on the set of lattice points as follows\\n(compare to [7, Section 1.3] and [24, Chapter 5]).\\nDeﬁnition 2.1. Let F ⊂Zd be a ﬁnite set and M ⊂Zd. The graph F(M) is the graph on\\nF where two nodes u, v ∈F are adjacent if u −v ∈M or v −u ∈M.\\nA normal set F ⊂Zd is ﬁnite and satisﬁes F = convQ(F)∩Zd. A canonical class of normal\\nsets that arise in many applications, is given by the ﬁbers of an integer matrix:\\nDeﬁnition 2.2. Let A ∈Zm×d and b ∈NA. The set FA,b := {u ∈Nd : Au = b} is the b-ﬁber\\nof A. The collection of all ﬁbers of A is PA := {FA,b : b ∈NA}. For M ⊂kerZ(A), the graph\\nFA,b (M) is a ﬁber graph.\\nLet F, M ⊂Zd be ﬁnite. If the membership in F can be veriﬁed eﬃciently – for instance\\nwhen F is given implicitly by linear equations and inequalities – then it is possible to explore\\nF randomly using M as follows: At a given node v ∈F, a uniform element m ∈M is\\nselected. If v + m ∈M, then the random walk moves along m to v + m and if v + m ̸∈M,\\nthe we stay at v. Formally, we obtain the following random walk.\\nDeﬁnition 2.3. Let F ⊂Zd and M ⊂Zd be two ﬁnite sets. The simple walk is the random\\nwalk on F(M) where the probability to traverse between to adjacent nodes u and v is |±M|−1\\nand the probability to stay at a node u is |{m ∈±M : u + m ̸∈F}| · | ± M|−1.\\nThe simple walk is symmetric and hence the uniform distribution is a stationary distribu-\\ntion (see also [27, Section 2]). To ensure convergence, the random walk has to be irreducible,\\nthat is, the underlying graph has to be connected. The following deﬁnition is a slight adaption\\nof the generalized Markov basis as deﬁned in [21, Deﬁnition 1].\\nDeﬁnition 2.4. Let P be a collection of ﬁnite subsets of Zd. A ﬁnite set M ⊂Zd is a\\nMarkov basis of P, if for all F ∈P, F(M) is a connected graph.\\n4\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nWe refer to [6, Theorem 3.1] for a proof that for collections PA, a ﬁnite Markov basis\\nalways exists and can be computed with tools from commutative algebra (see also [11] for\\nmore on the computation of Markov bases). We now introduce a construction of graphs on\\nlattice points that also give rise to implementable random walks, but whose edges have far\\nmore reach.\\nDeﬁnition 2.5. Let F ⊂Zd and M ⊂Zd be ﬁnite sets. The compression of the graph\\nF(M) is the graph Fc(M) := F(Z · M).\\nFigure 1. Compressing graphs.\\nCompressing a graph F(M) preserves its connectedness: F(M) is connected if and only\\nif Fc(M) is connected.\\n3. Bounds on the diameter\\nIn general knowledge of the diameter of the graph underlying a Markov chain can provide\\ninformation about the mixing time. For random walks on ﬁber graphs, the chains which we\\nconsider, the underlying graph coincides with the ﬁber graph. In this section, we determine\\nlower and upper bounds on the diameter of ﬁber graphs and their compressed counterparts.\\nFor a ﬁnite set M ⊂Zd and any norm ∥· ∥on Rd, let ∥M∥:= maxm∈M ∥m∥.\\nLemma 3.1. Let F ⊂Zd and M ⊂Zd be ﬁnite sets, then\\ndiam(F(M)) ≥\\n1\\n∥M∥· max{∥u −v∥: u, v ∈F}.\\nProof. If F(M) is not connected, then the statement holds trivially, so assume that M is a\\nMarkov basis for F. Let u′, v′ ∈F such that ∥u′ −v′∥= max{∥u −v∥: u, v ∈F} and let\\nm1, . . . , mr ∈M so that u′ = v′+Pr\\ni=1 mi is a path of minimal length, then ∥u′−v′∥≤r·∥M∥\\nand the claim follows from diam(F(M)) ≥distF(M)(u′, v′) = r.\\n□\\nRemark 3.2. Let F ⊂Zd be a normal set. For all l ∈{−1, 0, 1}d and u, v ∈F we have\\n(u −v)T l ≤∥u −v∥1 and thus widthl(F) := max{(u −v)T l : u, v ∈F} ≤max{∥u −v∥1 :\\nu, v ∈F}. Suppose that u′, v′ ∈F are such that ∥u′ −v′∥1 = max{∥u −v∥1 : u, v ∈F} and\\nlet l′\\ni := sign(u′\\ni −v′\\ni) for i ∈[d], then\\n∥u′ −v′∥1 = (u′ −v′)T · l′ ≤widthl′(F) ≤max{∥u −v∥1 : u, v ∈F} = ∥u′ −v′∥1.\\nThe lattice width of F is width(F) := minl∈Zd widthl(F) and thus Lemma 3.1 gives\\n∥M∥1 · diam(F(M)) ≥width(F).\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n5\\nDeﬁnition 3.3. Let P be a collection of ﬁnite subsets of Zd.\\nA ﬁnite set M ⊂Zd is\\nnorm-like for P if there exists a constant C ∈N such that for all F ∈P and all u, v ∈F,\\ndistF(M)(u, v) ≤C · ∥u −v∥. The set M is ∥· ∥-norm-reducing for P if for all F ∈P and all\\nu, v ∈F there exists m ∈M such that u + m ∈F and ∥u + m −v∥< ∥u −v∥.\\nThe property of being norm-like does not depend on the norm, whereas being norm-\\nreducing does.\\nNorm-reducing sets are always norm-like, and norm-like sets are in turn\\nalways Markov bases, but the reverse of both statements is false in general (Example 3.4 and\\nExample 3.5). For collections PA however, every Markov basis is norm-like (Proposition 3.7).\\nExample 3.4. For any n ∈N, consider the normal set Fn := ([2]×[n]×{0})∪{(2, n, 1)} with\\nthe Markov basis {(0, 1, 0), (0, 0, 1), (−1, 0, −1)}. The distance between (1, 1, 0) and (2, 1, 0)\\nin Fn(M) is 2n and thus M is not norm-like for {Fn : n ∈N} (see also Figure 2).\\nExample 3.5. Let d ∈N and consider A := (1, . . . , 1) ∈Z1×d, then the set M := {e1 −ei :\\n2 ≤i ≤d} is a Markov basis for the collection PA. However, M is not ∥·∥p-norm-reducing for\\nany d ≥3 and any p ∈[1, ∞]. For instance, consider e2 and e3 in FA,1 (M). The only move\\nfrom M that can be applied on e2 is e1−e2, but ∥(e2+e1−e2)−e3)∥p = ∥e2−e3∥p. On the other\\nhand, in the case we cannot ﬁnd a move that decreases the 1-norm of two nodes u, v ∈FA,b\\nby 1, we can ﬁnd instead two moves m1, m2 ∈M such that u + m1, u + m1 + m2 ∈FA,b and\\n∥u + m1 + m2 −v∥= ∥u −v∥−2. Thus, the graph-distance of any two elements u and v in\\nFA,b (M) is at most ∥u −v∥1 and hence M is norm-like for PA.\\nFigure 2. The graph from Example 3.4\\nRemark 3.6. Let P be a collection of ﬁnite subsets of Zd and M ⊂Zd be norm-like for P.\\nIt follows from the deﬁnition that there exists a constant C ∈Q≥0 such that for all F ∈P\\ndiam(F(M)) ≤C · max{∥u −v∥: u, v ∈F}.\\nThe proof of our next results uses the Graver basis GA ⊂Zd for an integer matrix A ∈Zm×d\\nwith kerZ(A) ∩Nd = {0}. We refer to [4, Chapter 3] for a precise deﬁnition.\\nProposition 3.7. Let A ∈Zm×d with kerZ(A) ∩Nd = {0} and M ⊂kerZ(A) be a Markov\\nbasis of PA. Then M is norm-like for PA.\\nProof. Let M be a Markov basis for PA. The Graver basis GA for A is a ﬁnite set which\\nis ∥· ∥1-norm-reducing for PA. Thus, deﬁne C := maxg∈GA diam(FA,Ag+ (M)). Now, pick\\nu, v ∈FA,b arbitrarily and let u = v + Pr\\ni=1 gi be a walk from u to v in FA,b (GA) of minimal\\nlength. Since the Graver basis is norm-reducing for FA,b, there always exists a path of length\\nat most ∥u −v∥1 and hence r ≤∥u −v∥1. Every gi can be replaced by a path in FA,Ag+\\ni (M)\\n6\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nof length at most C and these paths stay in FA,b. This gives a path of length C · r, hence\\ndistFA,b(M)(u, v) ≤C∥u −v∥1.\\n□\\nProposition 3.8. Let P ⊂Zd be a polytope with dim(P ∩Zd) > 0 and let M be a Markov\\nbasis for Fi := (i · P) ∩Zd for all i ∈N. There exists a constant C′ ∈Q>0 such that for all\\ni ∈N, C′ · i ≤diam(Fi(M)). If M is norm-like for {Fi : i ∈N}, then there exists a constant\\nC ∈Q>0 such that diam(Fi(M)) ≤C · i for all i ∈N.\\nProof. For the lower bound on the diameter, it suﬃces to show the existence of C′ such that\\nC′ · i ≤max{∥u −v∥: u, v ∈Fi} for all i ∈N due to Lemma 3.1. Since dim(P ∩Zd) > 0,\\nwe can pick distinct w, w′ ∈P ∩Zd. For all i ∈N, i · w, i · w′ ∈Fi and hence i · ∥w −w′∥≤\\nmax{∥u −v∥: u, v ∈Fi}.\\nTo show the upper bound, assume that M is norm-like. It suﬃces to show that there\\nexists C ∈Q≥0 such that max{∥u −v∥: u, v ∈Fi} ≤i · C by Remark 3.6.\\nNow, let\\nv1, . . . , vr ∈Qd such that P = convQ(v1, . . . , vr) and deﬁne C := max{∥vs −vt∥: s ̸= t}.\\nSince Fi = (i·P)∩Zd ⊂convQ(iv1, . . . , ivr) for all i ∈N, we have max{∥u−v∥: u, v ∈Fi} ≤\\nmax{∥ivs −ivt∥: s ̸= t} ≤C · i.\\n□\\nRemark 3.9. Let A ∈Zm×n with kerZ(A) ∩Nd = {0} and let M be a Markov basis for PA.\\nThen M is norm-like due to Proposition 3.7 and thus for all b ∈NA there exists C, C′ ∈Q≥0\\nsuch that\\ni · C′ ≤diam(FA,ib (M)) ≤i · C\\nfor all i ∈N. This generalizes for instance [20, Proposition 2.10] and [27, Example 4.7], where\\nlinear diameters on a ray in NA have been observed. This also implies that the construction\\nof expanders from [27, Section 4] works for every right-hand side b ∈NA.\\nRemark 3.10. Let A ∈Zm×d with kerZ(A)∩Nd = {0}, b ∈NA, and let M be a Markov basis\\nfor PA. Proposition 3.8 provides a new proof that the simple walk on (FA,ib (M))i∈N cannot\\nmix rapidly. The lower bound on the diameter from Proposition 3.8 implies, in general, the\\nfollowing upper bound on the edge-expansion (see for example [9, Proposition 1.30]):\\nh(FA,i·b (M)) ≤|M|\\n\\x12\\nexp\\n\\x12log |FA,i·b|\\nD · i\\n\\x13\\n−1\\n\\x13\\n.\\nIn particular, the edge-expansion cannot be bounded from below by Ω( 1\\np(i))i∈N for a polyno-\\nmial p ∈Q[t] and since (|FA,i·b|)i∈N ∈O(ir)i∈N, the simple walk cannot mix rapidly. In [27],\\nit was shown that the edge-expansion can be bounded from above by O(1\\ni )i∈N, which cannot\\nbe concluded from the upper expression.\\nWe now turn our attention to the diameter of compressed ﬁber graphs.\\nIn particular,\\nwe want to know for which collections of normal sets is their diameter bounded. In general,\\ncompressing a ﬁber graph does not necessarily have an eﬀect on the diameter (Example 3.11).\\nAlthough a low diameter is a necessary condition for good mixing, it is not suﬃcient. For\\ninstance, let Gn be the disjoint union of two complete graphs Kn connected by a single edge.\\nThen diam(Gn) = 3, but h(Gn) ≤1\\nn implies that the simple walk does not mix rapidly.\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n7\\nExample 3.11. For any n ∈N, let Fn := {(0, 0), (0, 1), (1, 1), (1, 2), . . . , (n, n)} ⊂Z2. The\\nunit vectors M = {e1, e2} are a Markov basis for {Fn : n ∈N}. However, Fc\\nn(M) = Fn(M)\\nand thus diam(Fc\\nn(M)) = diam(Fn(M)) = 2n is unbounded.\\nLemma 3.12. Let A ∈Zm×d and z ∈kerZ(A). There exists r ∈[2d −2], distinct elements\\ng1, . . . , gr ∈GA, and λ1, . . . , λr ∈N>0 such that z = Pr\\ni=1 λigi and gi ⊑z for all i ∈[r]\\nProof. This is [4, Lemma 3.2.3], although it only becomes clear from the original proof of [22,\\nTheorem 2.1] that the appearing elements are all distinct.\\n□\\nProposition 3.13. Let A ∈Zm×d and P :=\\n\\x08\\n{x ∈Zd : Ax = b, l ≤x ≤u} : l, u ∈Zd, b ∈Zm\\t\\n.\\nThen for all F ∈P, diam(Fc(GA)) ≤2d −2.\\nProof. Let s, t ∈{x ∈Zd : Ax = b, l ≤x ≤u}, then s−t ∈kerZ(A) and thus s = t+Pr\\ni=1 λigi\\nwith r ≤2d −2, λ1, . . . , λr ∈N>0, and distinct g1, . . . , gr ∈GA such that gi ⊑s −t according\\nto Lemma 3.12. It’s now a consequence from [4, Lemma 3.2.4] that all intermediate points\\nt + Pk\\ni=1 λigi for k ≤r are in {x ∈Zd : Ax = b, l ≤x ≤u}.\\n□\\nLemma 3.14. Let F ⊂Zd be ﬁnite and let Fi := (i · convQ(F)) ∩Zd for i ∈N. For all\\nu, v ∈F, distFc\\ni (M)(iu, iv) ≤distF(M)(u, v) for all i ∈N.\\nProof. The statement is trivially true if u and v are disconnected in F(M). Thus, assume\\nthe contrary and let u = v + Pk\\nj=1 mj with mj ∈M be a path in F(M) of length k =\\ndistF(M)(u, v) and let i ∈N. Clearly, i · u = i · v + i · Pk\\nj=1 mj = i · v + Pk\\nl=1 i · mj, so\\nit is left to prove that the elements traversed by this paths are in Fi. Let l ∈[k], since\\nv + Pl\\nj=1 mj ∈F, we have i · v + Pl\\nj=1 i · mj ∈i · F ⊆Fi. Hence, this is a path in Fc\\ni (M)\\nof length k = distF(M)(u, v).\\n□\\nWe are ready to prove that the diameter of compressed ﬁber graphs coming from an integer\\nmatrix can be bounded for all right-hand sides simultaneously.\\nTheorem 3.15. Let A ∈Zm×d with kerZ(A) ∩Nd = {0} and let M be a Markov basis for\\nPA. There exists a constant C ∈N such that diam(Fc(M)) ≤C for all F ∈PA.\\nProof. Our proof relies on basic properties of the Graver basis GA of A. For any g ∈GA,\\nlet Fg := FA,Ag+ and let K := max{distFg(M)(g+, g−) : g ∈GA}.\\nWe show that the\\ndiameter of any compressed ﬁber graph of A is bounded from above by (2d −2) · K. Let\\nb ∈NA arbitrary and choose elements u, v ∈FA,b. According to Proposition 3.13, there\\nexists r ∈[2d −2], g1, . . . , gr ∈GA and λ1, . . . , λr ∈Z such that u = v + Pr\\ni=1 λigi, and\\nv + Pl\\ni=1 λigi ∈Nd for all l ∈[r].\\nAccording to Lemma 3.14, for any i ∈[r] there are\\nmi\\n1, . . . , mi\\nki ∈M and α1, . . . , αki ∈Z such that λig+\\ni = λig−\\ni + Pki\\nj=1 αjmi\\nj is a path in the\\ncompression of FA,Aλig+\\ni (M) of length ki ≤K. Lifting these paths for every i ∈[r] yields a\\npath u = v + Pr\\ni=1\\nPki\\nj=1 αjmi\\nj in Fc\\nA,b (M) of length r · K ≤(2d −2) · K.\\n□\\n8\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\n4. Heat-bath random walks\\nIn this section, we establish the heat-bath random walk on compressed ﬁber graphs. We\\nrefer to [8] for a more general introduction on random walks of heat-bath type. Let F ⊂Zd\\nbe ﬁnite set. For any u ∈F and m ∈Zd, the ray in F through u along m is denoted by\\nRF,m(u) := (u + m · Z) ∩F. Additionally, given a mass function π : F →[0, 1], we deﬁne\\nHπ\\nF,m(x, y) :=\\n(\\nπ(y)\\nπ(RF,m(x))\\n, if y ∈RF,m(x)\\n0\\n, otherwise\\nfor x, y ∈F. For M ⊂Zd and a mass function f : M →[0, 1], the heat-bath random walk is\\n(4.1)\\nHπ,f\\nF,M =\\nX\\nm∈M\\nf(m) · Hπ\\nF,m.\\nThe underlying graph of the heat-bath random walk is the compression Fc(M) and in this\\nsection, we assume throughout that for all m ∈M and λ ∈Z \\\\ {−1, 1}, λ · m ̸∈M. Let us\\nﬁrst recall the basic properties of this random walk (compare also to [6, Lemma 2.2]).\\nAlgorithm 1 Heat-bath random walk on compressed ﬁber graphs\\nInput: F ⊂Zd, M ⊂Zd, v ∈F, mass functions f : M →[0, 1] and π : F →[0, 1], r ∈N\\n1: procedure HeatBath:\\n2:\\nv0 := v\\n3:\\nFOR s = 0; s = s + 1, s < r\\n4:\\nSample m ∈M according to f\\n5:\\nSample vs+1 ∈RF,m(vs) according to RF,m(vs) →[0, 1], y 7→\\nπ(y)\\nπ(RF,m(vs))\\n6:\\nRETURN v1, . . . , vr\\nProposition 4.1. Let F ⊂Zd and M ⊂Zd be ﬁnite sets. Let f : M →[0, 1] and π : F →\\n(0, 1) be mass functions. Then Hπ,f\\nF,M is aperiodic, has stationary distribution π, is reversible\\nwith respect to π, and all of its eigenvalues are non-negative. The random walk is irreducible\\nif and only if {m ∈M : f(m) > 0} is a Markov basis for F.\\nProof. Since for any u ∈F and any m ∈M, Hπ\\nF,m(u, u) > 0, there are halting states and\\nthus Hπ,f\\nF,M is aperiodic. By deﬁnition, π(x)Hπ\\nF,m(x, y) = π(y)Hπ\\nF,m(y, x) and thus Hπ,f\\nF,M\\nis reversible with respect to π and π is a stationary distribution.\\nThe statement on the\\neigenvalues is exactly [8, Lemma 1.2]. Let M′ = {m ∈M : f(m) > 0} and f ′ = f|M′, then\\nHπ,f\\nF,M = Hπ,f′\\nF,M′ and thus the heat-bath random walk is irreducible if and only if M′ is a\\nMarkov basis for F.\\n□\\nRemark 4.2. Analyzing the speed of convergence of random walks with second largest\\neigenvalues does not take the computation time of a single transition into account. From\\na computational point of view, the diﬀerence of the simple walk and the heat-bath random\\nwalk is Step 4 of Algorithm 1. However, we argue that Step 4 can be done eﬃciently in\\nmany cases. For instance, a hard normalizing constant of π cancels out. If π is the uniform\\ndistribution, then one needs to sample uniformly from RF,m(v) in Step 4, which can be done\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n9\\neﬃciently. If the input of Algorithm 1 is a normal set F = {u ∈Zd : Au ≤b} that is given\\nin H-representation, then the length of the ray RF,m(v) can be computed with a number of\\nrounding, division, and comparing operations that is linear in the number of rows of A.\\nThere are situations in which the heat-bath random walk provides no speed-up compared\\nwith the simple walk (Example 4.3). Intuitively, adding more moves to the set of allowed\\nmoves should improve the mixing time of the random walk. In general, however, this is not\\ntrue for the heat-bath walk (Example 4.4).\\nExample 4.3. For n ∈N, consider the normal set\\nFn :=\\n\\x1a\\x14\\n0\\n1\\n1\\n· · ·\\n1\\n1\\n0\\n0\\n· · ·\\n0\\n\\x15\\n,\\n\\x14\\n1\\n0\\n1\\n· · ·\\n1\\n0\\n1\\n0\\n· · ·\\n0\\n\\x15\\n, . . . ,\\n\\x14\\n1\\n1\\n· · ·\\n1\\n0\\n0\\n0\\n· · ·\\n0\\n1\\n\\x15\\x1b\\n⊂Q2×n.\\nIn the language of [7, Section 1.1], Fn is precisely the ﬁber of the 2 × n independence model\\nwhere row sums are (n −1, 1) and column sums are (1, 1, . . . , 1).\\nThe minimal Markov\\nbasis of the independence model, often referred to as the basic moves, is precisely the set\\nMn := {v −u : u, v ∈Fn} \\\\ {0}. In particular, the ﬁber graph Fn(Mn) is the complete\\ngraph on n nodes. All rays along basic moves have length 2 and thus the transition matrices\\nof the simple random walk and the heat-bath random walk coincide. There are n · (n −1)\\nmany basic moves and the transition matrix of both random walks is\\n1\\nn(n −1)\\n\\uf8ee\\n\\uf8ef\\uf8f0\\n1\\n. . .\\n1\\n...\\n...\\n1\\n. . .\\n1\\n\\uf8f9\\n\\uf8fa\\uf8fb+ (n(n −1) −n)\\nn(n −1)\\n· In.\\nThe second largest eigenvalue is 1 −\\n1\\nn−1 which implies that for n →∞, neither the simple\\nwalk nor the heat-bath random walk are rapidly mixing.\\nExample 4.4. Let F = [2] × [5] ⊂Z2, M = {e1, e2, 2e1 + e2}, and let π be the uniform\\ndistribution on F.\\nSince {e2, 2e1 + e2} is not a Markov basis for F, any mass function\\nf : M →[0, 1] must have f(e1) > 0 in order to make the corresponding heat-bath random\\nwalk irreducible.\\nComparing the second largest eigenvalue modulus of heat-bath random\\nwalks that sample from {e1, e2} and M uniformly, we obtain\\nλ\\n\\x121\\n2Hπ\\nF,e1 + 1\\n2Hπ\\nF,e2\\n\\x13\\n= 1\\n2 < 2\\n3 = λ\\n\\x121\\n3Hπ\\nF,e1 + 1\\n3Hπ\\nF,e2 + 1\\n3Hπ\\nF,2e1+e2\\n\\x13\\n.\\nSo, adding 2e1 + e2 to the set of allowed moves slows the walk down. This phenomenon does\\nnot appear for the simple walk on F, where the second largest eigenvalue modulus improves\\nfrom ≈0.905 to ≈0.888 when adding the move 2e1 + e2 to the Markov basis.\\n=\\n+\\n+\\nFigure 3. Decomposition of the graph in Example 4.4\\n10\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nRemark 4.5. Let F ⊂Zd be ﬁnite and M = {m1, . . . , md} ⊂Zd be a linearly independent\\nMarkov basis of F. If the moves are selected uniformly, then the heat-bath random walk on\\nF coincides with the Glauber dynamics on F. To see it, choose u ∈F and let\\nF′ := {λ ∈Zd : u + λ1m1 + · · · + λdmd ∈F}.\\nIt is easy to check that F′ is unique up to translation and depends only on F, u, and M.\\nSince the vectors in M are linearly independent, every element of F can be represented by\\na unique choice of coeﬃcients in F′. Thus, the heat-bath random walk on F using M is\\nequivalent to the heat-bath random walk on on F′ using the unit vectors as moves. For any\\nunit vector ei ∈Zd, the ray through an element v ∈F′ is {w ∈F : wj = vj∀j ̸= i} and this\\nis precisely the form desired in the Glauber dynamics [14, Section 3.3.2].\\nFor the remainder of this section, we primarily focus on heat-bath random walks Hπ,f\\nF,M\\nthat converge to the uniform distribution π on a ﬁnite, but not necessarily normal, set\\nF. We particularly aim for bounds on its second largest eigenvalue by making use of the\\ndecomposition from equation 4.1. Our ﬁrst observations consider its summands Hπ\\nF,m that\\ncan be well understood analytically (Proposition 4.6) and combinatorially (Proposition 4.7).\\nProposition 4.6. Let F ⊂Zd be a ﬁnite set, m ∈Zd, and π : F →[0, 1] be the uniform\\ndistribution. Let R1, . . . , Rk be the disjoint rays through F along m. Then\\n1. Hπ\\nF,m is symmetric and idempotent.\\n2. img(Hπ\\nF,m) = spanR\\nnP\\nx∈R1 ex, P\\nx∈R2 ex, . . . , P\\nx∈Rk ex\\no\\n.\\n3. ker(Hπ\\nF,m) = Lk\\ni=1 spanR {ex −ey : x, y ∈Ri, x ̸= y}.\\n4. rank(Hπ\\nF,m) = k and dim ker(Hπ\\nF,m) = |F| −k.\\n5. The spectrum of Hπ\\nF,m is {0, 1}.\\nProof. Symmetry of Hπ\\nF,m follows from the deﬁnition. By assumption, F is the disjoint union\\nof R1, . . . , Rk and hence there exists a permutation matrix S such that SHπ\\nF,mST is a block\\nmatrix whose building blocks are the matrices\\n1\\n|Ri|\\n\\uf8ee\\n\\uf8ef\\uf8f0\\n1\\n. . .\\n1\\n...\\n...\\n1\\n. . .\\n1\\n\\uf8f9\\n\\uf8fa\\uf8fb∈Q|Ri|×|Ri|.\\nThus, Hπ\\nF,m is idempotent and the rank of Hπ\\nF,m is k. A basis of its image and its kernel can\\nbe read oﬀdirectly and idempotent matrices can only have the eigenvalues 0 and 1.\\n□\\nProposition 4.7. Let F ⊂Zd and M ⊂Zd be ﬁnite sets, π : F →[0, 1] be the uniform\\ndistribution, and let V1, . . . , Vc ⊆F be the nodes of the connected components of F(M), then\\n\\\\\\nm∈M\\nimg(Hπ\\nF,m) = spanR\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nX\\nx∈V1\\nex, . . . ,\\nX\\nx∈Vc\\nex\\n\\uf8fc\\n\\uf8fd\\n\\uf8fe.\\nProof. It is clear by Proposition 4.6 that the set on the right-hand side is contained in any\\nimg(Hπ\\nF,m) since any Vi decomposes disjointly into rays along m ∈M. To show the other\\ninclusion, write M = {m1, . . . , mk} and let for any i ∈[k], Ri\\n1, . . . , Ri\\nni be the disjoint rays\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n11\\nthrough F parallel to mi. In particular, {Ri\\n1, . . . , Ri\\nni} is a partition of F for any i ∈[k]. Let\\nv ∈T\\nm∈M img(Hπ\\nF,m). Again by Proposition 4.6, there exists for any i ∈[k], λi\\n1, . . . , λi\\nni ∈Q\\nsuch that\\nv =\\nni\\nX\\nj=1\\nX\\nx∈Ri\\nj\\nλi\\njex.\\nNotice that if two distinct Markov moves mi and mi′ and two indices j ∈[ni] and j′ ∈[ni′]\\nsatisfy Ri\\nj ∩Ri′\\nj′ ̸= ∅, then λi\\nj = λi′\\nj′. We show that for any i ∈[k] and any a ∈[c], λi\\nj = λi\\nj′\\nwhen Ri\\nj and Ri\\nj′ are a subset of Va. This implies the proposition. So take distinct x, x′ ∈Va\\nand assume that x and x′ lie on diﬀerent rays of mi and let that be x ∈Ri\\nj and x′ ∈Ri\\nj′ with\\nj ̸= j′. Since x and x′ are in the same connected component Va of F(M), let yi0, . . . , yir ∈F\\nbe the nodes on a minimal path in Fc(M) with yi0 = x and yir = x′. For any s ∈[r], yis\\nand yis−1 are contained in the same ray Rks\\nts coming from a Markov move mks. In particular,\\nRts−1\\nks−1 ∩Rks\\nts ̸= ∅and due to our observation made above λi\\nj = λk1\\nt1 = λk2\\nt2 = · · · = λkr\\ntr = λi\\nj′\\nwhich ﬁnishes the proof.\\n□\\nDeﬁnition 4.8. Let F ⊂Zd and M ⊂Zd be ﬁnite sets and M′ ⊆M. Let V be the set of\\nconnected components of F(M\\\\M′) and R be the set of all rays through F along all elements\\nof M′. The ray matrix of F(M) along M′ is AF(M, M′) := (|R ∩V |)R∈R,V ∈V ∈NR×V.\\nExample 4.9. Let F = [3]×[3], M = {e1, e2, e1 +e2}, and M′ = {e1, e2}. Then F(M\\\\M′)\\nhas ﬁve connected components and the ray matrix of F(M) along M′ is\\nAF(M, M′) =\\n\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0\\n1\\n1\\n1\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n1\\n1\\n0\\n1\\n1\\n1\\n0\\n0\\n\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\n.\\nRemark 4.10. Let F ⊂Z2, then the rays through F along e1 are the connected components\\nof F({e1, e2} \\\\ {e2}) and the rays through F along e2 are the connected components of\\nF({e1, e2} \\\\ {e1}), thus AF(M, e1) = AF(M, e2)T .\\nProposition 4.11. Let F ⊂Zd and M ⊂Zd be ﬁnite sets, π : F →[0, 1] be the uniform\\ndistribution, and M′ ⊆M. Then\\nker(AF(M, M′)) ∼=\\n\\\\\\nm∈M\\\\M′\\nimg(Hπ\\nF,m) ∩\\n\\\\\\nm∈M′\\nker(Hπ\\nF,m).\\nProof. Let V1, . . . , Vc be the connected components of F(M \\\\ M′) and R1, . . . , Rr be the\\nrays along elements in M′. Let I := T\\nm∈M\\\\M′ img(Hπ\\nF,m) and K := T\\nm∈M′ ker(Hπ\\nF,m). By\\nProposition 4.7, any element of I has the form v = Pc\\ni=1(λi\\nP\\nx∈Vi ex) for λ1, . . . , λc ∈Q.\\nAssume additionally that v ∈ker(Hπ\\nF,m) for m ∈M′ and let Ri1, . . . Rij be the rays which\\nbelong to m, then for any k ∈[j], 0 = P\\nx∈Rik vx = Pc\\nj=1 λj|Rik∩Vj|. Put diﬀerently, a vector\\nλ ∈Rc is in the kernel of (|Ri ∩Vj|)i∈[r],j∈[c] if and only if Pc\\ni=1(λi\\nP\\nx∈Vi ex) ∈I ∩K.\\n□\\n12\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nConditions on the kernel of the ray matrix allow us to give a lower bound on the second\\nlargest eigenvalue of the heat-bath random walk.\\nProposition 4.12. Let F ⊂Zd and M ⊂Zd be ﬁnite sets and π be the uniform distribution.\\nLet M′ ⊆M such that ker(AF(M, M′)) ̸= {0}, then λ(Hπ,f\\nF,M) ≥1 −P\\nm∈M′ f(m) for any\\nmass function f : M →[0, 1].\\nProof. Using the isomorphism from Proposition 4.11, we can choose a non-zero v ∈QP such\\nthat Hπ\\nF,mv = v for all m ∈M \\\\ M′ and Hπ\\nF,mv = 0 for all m ∈M′. In particular\\nHπ,f\\nF,Mv =\\nX\\nm∈M\\nf(m)Hπ\\nF,mv =\\nX\\nm∈M\\\\M′\\nf(m)Hπ\\nF,mv =\\nX\\nm∈M\\\\M\\nf(m)v.\\nSince f is a mass function, 1 −P\\nm∈M′ f(m) is an eigenvalue of Hπ,f\\nF,M.\\n□\\nDeﬁnition 4.13. Let F ⊂Zd and m, m′ ∈Zd not collinear.\\nThe pair (m, m′) has the\\nintersecting ray property in F if the following holds: For any pair of rays R1, R2 parallel\\nto m and any pair of rays R′\\n1, R′\\n2 parallel to m′ where both R1 ∩R′\\n1 and R2 ∩R′\\n2 are not\\nempty, then R1 ∩R′\\n2 ̸= ∅implies R′\\n1 ∩R2 ̸= ∅and |R1| · |R′\\n1|−1 = |R2| · |R′\\n2|−1. For a\\nﬁnite set M ⊂Zd, the graph Fc(M) has the intersecting ray property if all (m, m′) have the\\nintersecting ray property in F.\\nExample 4.14. The compressed ﬁber graph on [n1] × · · · × [nd] ⊂Zd that uses the unit\\nvectors {e1, . . . , ed} as moves has the intersecting ray property. On the other hand, consider\\nF = {u ∈N2 : u1 + u2 ≤1} and take the rays R1 := {(0, 0), (0, 1)} and R2 := {(1, 0)}\\nthat are parallel to e2 and the rays R′\\n1 := {(0, 1)} and R′\\n2 := {(0, 0), (1, 0)} that are parallel\\nto e1. Then R1 ∩R′\\n1 = {(1, 0)} and R2 ∩R′\\n2 = {(0, 1)}, but R1 ∩R′\\n2 = {(0, 0)} ̸= ∅and\\nR′\\n1 ∩R2 = ∅.\\nProposition 4.15. Let m, m′ ∈Zd not collinear and F ⊂Zd be a ﬁnite set. The matrices\\nHπ\\nF,m and Hπ\\nF,m′ commute if and only if (m, m′) have the intersecting ray property in F.\\nProof. Let u1, u2 ∈F. Then\\n(Hπ\\nF,m · Hπ\\nF,m′)u1,u2 =\\n(\\n|RF,m(u1)|−1 · |RF,m′(u2)|−1,\\nif RF,m(u1) ∩RF,m′(u2) ̸= ∅\\n0,\\notherwise\\n.\\nLet R1 := RF,m(u1), R′\\n1 := RF,m′(u1), R2 := RF,m(u2), and R′\\n2 := RF,m′(u2) Thus,\\n(Hπ\\nF,m · Hπ\\nF,m′)u1,u2 = (Hπ\\nF,m′ · Hπ\\nF,m)u1,u2. It is easy to see that the matrices commute if and\\nonly if (m, m′) have the intersecting ray property.\\n□\\nLemma 4.16. Let H1, . . . , Hn ∈Rn×n be pairwise commuting matrices. Then any eigenvalue\\nof Pn\\ni=1 Hi has the form λ1 + · · · + λn where λi is an eigenvalue of Hi.\\nProof. This is a straightforward extension of the case n = 2 in [12, Theorem 2.4.8.1] and\\nrelies on the fact that commuting matrices are simultaneously triangularizable.\\n□\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n13\\nProposition 4.17. Let F ⊂Zd and M ⊂Zd be ﬁnite sets and suppose there exists m ∈M\\nsuch that (m, m′) has the intersecting ray property in F for all m′ ∈M′ := M \\\\ {m}. Let\\nV1, . . . , Vc be the connected components of F(M′), πi : Vi →[0, 1] the uniform distribution,\\nand f ′ = (1 −f(m))−1 · f|M′, then\\nλ(Hπ,f\\nF,M) ≤f(m) + (1 −f(m)) · max{λ(Hπi,f′\\nVi,M′) : i ∈[c]}.\\nProof. Let H := Hπ,f′\\nF,M′ be the heat-bath random walk on F(M) that samples moves from M′\\naccording to f ′, then Hπ,f\\nF,M = f(m)·Hπ\\nF,m +(1−f(m))·H. By assumption, all pairs (m, m′)\\nwith m′ ∈M′ have the intersecting ray property and thus the matrices Hπ\\nF,m and H commute\\naccording to Proposition 4.15. The eigenvalues of all involved matrices are non-negative and\\nthus Lemma 4.16 implies that the second largest eigenvalue of Hπ,f\\nF,M has the form λ + λ′\\nwhere λ ∈{0, f(m)} by Proposition 4.6 and where λ′ is an eigenvalue of (1 −f(m)) · H. The\\nmatrix H is a block matrix whose building blocks are the matrices Hπ,f′\\nVi,M′ = Hπi,f′\\nVi,M′ and thus\\nthe statement follows.\\n□\\nProposition 4.18. Let F ⊂Zd and M ⊂Zk be ﬁnite sets. If F(M) has the intersecting\\nray property, then λ(Hπ,f\\nF,M) ≤1 −min(f).\\nProof. Let M = {m1, . . . , mk}.\\nThe intersecting ray property and Proposition 4.15 give\\nthat the matrices f(m1) · Hπ\\nF,mi, . . . , f(mk) · Hπ\\nF,mk commute pairwise. According to Propo-\\nsition 4.6, the eigenvalues of f(mi) · Hπ\\nF,mi are {0, f(mi)}. Lemma 4.16 gives that the second\\nlargest eigenvalue of Hπ,f\\nF,M, which equals the second largest eigenvalue modulus since all of\\nits eigenvalues are non-negative, fulﬁlls λ(Hπ,f\\nF,M) = P\\ni∈I f(mi) for a subset I ⊆[k]. Since\\nλ(Hπ,f\\nF,M) < 1 and Pk\\ni=1 f(mi) = 1, we have I ̸= [k] and the claim follows.\\n□\\nProposition 4.19. Let n1, . . . , nd ∈N>1, F = [n1]×· · ·×[nd], and M = {e1, . . . , ed}. Then\\nfor any positive mass function f : M →[0, 1], λ(Hπ,f\\nF,M) = 1 −min(f).\\nProof. It is easy to verify that Fc(M) has the intersecting ray property and thus Proposi-\\ntion 4.18 shows λ(Hπ,f\\nF,M) ≤1−min(f). Assume that min(f) = f(ei). The connected compo-\\nnents of Fc({e1, . . . , ed} \\\\ {ei}) are the layers Vj := {u ∈F : ui = j} for any j ∈[ni] and the\\nrays through F parallel are Rk := {(0, k)+s·ei : s ∈[ni]} for k = (k1, . . . , ki−1, ki+1, . . . , kd) ∈\\n[n1] × · · · × [ni−1] × [ni+1] × · · · × [nd]. In particular, any ray intersects any connected com-\\nponent exactly once.\\nThus, the matrix (|Rk ∩Vj|)k,j is the all-ones matrix, which has a\\nnon-trivial kernel. Proposition 4.12 implies λ(Hπ,f\\nF,M) ≥1 −f(ei).\\n□\\nRemark 4.20. In the special case n := n1 = · · · = nd and f : {e1, . . . , ed} →[0, 1] the\\nuniform distribution in Proposition 4.19, the heat-bath random walk on [n]d is known as\\nRook’s walk in the literature. In this case, Proposition 4.19 is exactly [13, Proposition 2.3].\\nIn [18], upper bounds on the mixing time of the Rook’s walk were obtained with path-coupling.\\nThe stationary distribution of the heat-bath random walk is independent of the actual\\nmass function on the Markov moves. The problem of ﬁnding the mass function which leads\\n14\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nto the fastest mixing behaviour can be formulated as the following optimization problem:\\n(4.2)\\narg min\\n(\\nλ(Hπ,f\\nF,M) : f : M →(0, 1),\\nX\\nm∈M\\nf(m) = 1\\n)\\n.\\nIt follows from Proposition 4.19 that the optimal value of (4.2) for F = [n1] × · · · × [nd],\\nM = {e1, . . . , ed}, and the uniform distribution π on F is the uniform distribution on M.\\nAnother example where the uniform distribution is the optimal solution to (4.2), but where\\nthe veriﬁcation is more involved, is presented in Example 4.21.\\nExample 4.21. Let F = [2] × [5] as in Example 4.4 and consider M = {e1, 2e1 + e2}. We\\ninvestigate for which µ ∈(0, 1), the transition matrix µHπ\\nF,e1 + (1 −µ)Hπ\\nF,2e1+e2 has the\\nsmallest second largest eigenvalue modulus. Its characteristic polynomial in Q[µ, x] is\\n−1\\n25x4(x −1)(µ + x −1)6(−5x2 + 5x + 2µ2 −2µ)(−5x2 + 5x + 4µ2 −4µ)\\nand hence its eigenvalues are\\nx1(µ) := 1,\\nx2(µ) := 1 −µ,\\nx3(µ) := 1\\n2\\n\"\\n1 +\\nr\\n1 + 8\\n5(µ2 −µ)\\n#\\n,\\nx4(µ) := 1\\n2\\n\"\\n1 −\\nr\\n1 + 8\\n5(µ2 −µ)\\n#\\n,\\nx5(µ) := 1\\n2\\nh\\n1 +\\np\\n1 + 4(µ2 −µ)\\ni\\n,\\nx6(µ) := 1\\n2\\nh\\n1 −\\np\\n1 + 4(µ2 −µ)\\ni\\n.\\nIt is straightforward to check that x5(µ) > 1\\n2 > x6(µ), x3(µ) > 1\\n2 > x4(µ). Since µ2 −µ < 0\\nfor u ∈(0, 1) and x3(µ) ≥x6(µ). We can show that x4(µ) ≥x2(µ) and thus\\nλ(µHπ\\nF,e1 + (1 −µ)Hπ\\nF,2e1+e2) = 1\\n2\\n\"\\n1 +\\nr\\n1 + 8\\n5(µ2 −µ)\\n#\\n.\\nThe fastest heat-bath random walk on F(M) which converges to uniform is thus obtained for\\nµ = 1\\n2, i.e. when the moves are selected uniformly. The second largest eigenvalue in this case\\nis\\n1\\n10(5 +\\n√\\n15) ≈0.887, which is larger than the second largest eigenvalue of the heat-bath\\nwalk that selects uniformly from {e1, e2} (see Proposition 4.19).\\n5. Augmenting Markov bases\\nIt follows from our investigation in Section 3 that the diameter of all compressed ﬁber\\ngraphs coming from a ﬁxed integer matrix A ∈Zm×d can be bounded from above by a\\nconstant. However, Markov moves can be used twice in a minimal path which can make the\\ndiameter of the compressed ﬁber graph larger than the size of the Markov basis. The next\\ndeﬁnition puts more constraints on the Markov basis and postulates the existence of a path\\nthat uses every move from the Markov basis at most once.\\nDeﬁnition 5.1. Let F ⊂Zd be a ﬁnite set and M = {m1, . . . , mk} ⊂Zd. An augmenting\\npath between distinct u, v ∈F of length r ∈N is a path in Fc(M) of the form\\nu →u + λi1mi1 →u + λi1mi1 + λi2mi2 →· · · →u +\\nr\\nX\\nk=1\\nλikmik = v\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n15\\nwith distinct indices i1, . . . , ir ∈[k]. An augmenting path is minimal for u, v ∈F if there\\nexists no shorter augmenting path between u and v in Fc(M).\\nA Markov basis M for\\nF is augmenting if there is an augmenting path between any distinct nodes in F.\\nThe\\naugmentation length AM(F) of an augmenting Markov basis M is the maximum length of\\nall minimal augmenting paths in Fc(M).\\nNot every Markov basis is augmenting (see Example 3.11), but the diameter of compressed\\nﬁber graphs that use an augmenting Markov basis is at most the number of the moves. For\\nﬁber graphs coming from an integer matrix, an augmenting Markov basis for all of its ﬁbers\\ncan be computed (Remark 5.2).\\nRemark 5.2. Let A ∈Zm×d with kerZ(A) ∩Nd = {0} and let b ∈NA. The Graver basis\\nis an augmenting Markov basis for FA,b for any b ∈NA. We claim that when A is totally\\nunimodular, then AGA(FA,b) ≤d2(rank(A) + 1).\\nIn particular, the augmentation length\\nis independent of the right-hand side b.\\nLet u, v ∈FA,b be arbitrary and for i ∈N, let\\nli := min{ui, vi}, wi := max{ui, vi}, and ci := sign(ui −vi) ∈{−1, 0, 1}. Then v is the unique\\noptimal value of the linear integer optimization problem\\nmin{cT x : Ax = b, l ≤x ≤w, x ∈Zd}.\\nA discrete steepest decent as deﬁned in [5, Deﬁnition 3] using Graver moves needs at most\\n∥c∥1 · d · (rank(A) + 1) ≤d2 · (rank(A) + 1) many augmentations from u to reach the optimal\\nvalue v. We refer to [5, Corollary 8] which ensures that every Graver move is used at most\\nonce. Note that in [5], x is constrained to x ≥0 instead to x ≥l, but their argument works\\nfor any lower bound.\\nExample 5.3. Fix d ∈N and consider A and M from Example 3.5. We show that M is an\\naugmenting Markov basis for FA,b for any b ∈N. Let u, v ∈FA,b be distinct, then there exists\\ni ∈[d] such that ui > vi or ui < vi, thus, we can walk from u to u′ := u + (ui −vi)(e1 −ei)\\nor from v to v′ := v + (vi −ui)(e1 −ei). In any case, after that augmentation, the pairs\\n(u′, v) and (v′, u) coincide in the ith coordinate and thus we ﬁnd an augmenting path by\\ninduction on the dimension d. We have used at most d −1 many edges in these paths and\\nhence AM(FA,b) ≤d −1 for all b ∈N.\\nWe now show that the augmentation length is essentially bounded from below by the\\ndimension of the node set and hence the bound observed in Example 5.3 cannot be improved.\\nWe ﬁrst need the following lemma.\\nLemma 5.4. Let v1, . . . , vk ∈Qd such that any v ∈spanQ {v1, . . . , vk} can be represented by\\na linear combination of r vectors. Then dim(spanQ {v1, . . . , vk}) ≤r.\\nProof. Let B ⊂P(v1, . . . , vk) the set of all subsets of cardinality r. By our assumption,\\n∪B∈BspanQ {B} = spanQ {v1, . . . , vk}. Since dim(spanQ {B}) ≤r for all B ∈B and since B\\nis ﬁnite, the claim follows.\\n□\\nProposition 5.5. Let P ⊂Qd be polytope and let M ⊂Zd be an augmenting Markov basis\\nfor Fi := (i · P) ∩Zd for all i ∈N. Then dim(P) ≤maxi∈N AM(Fi).\\n16\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nProof. Without restricting generality, we can assume that 0 ∈P. Let V := spanQ {P} be\\nthe Q-span of P, then dim(P) = dim(V ). We must have dim(spanQ {M}) = dim(V ) since\\ndim(P) = dim(convQ(Fi)) for i suﬃciently large and since M is a Markov basis for Fi. Deﬁne\\nr := maxi∈N AM(Fi) and choose any non-zero v ∈V and u ∈relint(P) ⊂Qd. Then there\\nexists δ ∈Q>0 such that u + δv ∈P. Thus, 1\\nδu + v ∈1\\nδP. Let c ∈N≥1 such that i := c\\nδ ∈N\\nand w := c\\nδu ∈Zd. Then w + cv = c(1\\nδ u + v) ∈(i · P) ∩Zd = Fi. By assumption, there exists\\nan augmenting path from w to w + cv using only r elements from M. Put diﬀerently, the\\nelement cv from V can be represented by a linear combination of r vectors from M. Since v\\nwas chosen arbitrarily, Lemma 5.4 implies dim(P) = dim(V ) ≤r.\\n□\\nRemark 5.6. It is a consequence from Proposition 5.5 that for any matrix A ∈Zm×d with\\nkerZ(A) ∩Nd = {0} and an augmenting Markov basis M, there exists F ∈PA such that\\nAM(F) ≥dim(kerZ(A)).\\nLet us now shortly recall the framework from [23] which is necessary to prove our main\\ntheorem. Let G = (V, E) be a graph. For any ordered pair of distinct nodes (x, y) ∈V × V ,\\nlet px,y ⊆E be a path from x to y in G and let Γ := {px,y : (x, y) ∈V × V, x ̸= y} be\\nthe collection of these paths, then Γ is a set of canonical paths. Let for any edge e ∈E,\\nΓe := {p ∈Γ : e ∈p} be the set of paths from Γ that use e. Now, let H : V × V →[0, 1] be a\\nsymmetric random walk on G and deﬁne\\nρ(Γ, H) := max{|p| : p ∈Γ}\\n|V |\\n· max\\n{u,v}∈E\\n|Γ{u,v}|\\nH(u, v).\\nObserve that symmetry of H is needed to make ρ(Γ, H) well-deﬁned. This can be used to\\nprove the following upper bound on the second largest eigenvalue.\\nLemma 5.7. Let G be a graph, H be a symmetric random walk on G, and Γ be a set of\\ncanonical paths in G. Then λ2(H) ≤1 −\\n1\\nρ(Γ,H).\\nProof. The stationary distribution of H is the uniform distribution and thus the statement\\nis a direct consequence of [23, Theorem 5], since ρ(Γ, H) is an upper bound on the constant\\ndeﬁned in [23, equation 4].\\n□\\nTheorem 5.8. Let F ⊂Zd be ﬁnite and let M := {m1, . . . , mk} ⊂Zd be an augmenting\\nMarkov basis. Let π be the uniform and f be a positive distribution on F and M respectively.\\nFor i ∈[k], let ri := max{|RF,mi(u)| : u ∈F} and suppose that r1 ≥r2 ≥· · · ≥rk. Then\\nλ(Hπ,f\\nM,F) ≤1 −\\n|F| · min(f)\\nAM(F) · AM(F)! · 3AM(F)−1 · 2|M| · r1r2 · · · rAM(F)\\n.\\nProof. Choose for any distinct u, v ∈F an augmenting path pu,v of minimal length in Fc(M)\\nand let Γ be the collection of all these paths. Let u + µmk = v be an edge in Fc(M), then\\nour goal is to bound |Γ{u,v}| from above. Let S := {S ⊆[r] : |S| ≤AM(F), k ∈S} and take\\nany path px,y ∈Γ{u,v}. Then there exists S := {i1, . . . , is} with s := |S| ≤AM(F) such that\\nx + Ps\\nk=1 λikmik = y. Since px,y uses the edge {u, v}, there is j ∈[s] such that ij = k and\\nλij = µ. Since |λik| ≤rik, there are at most\\ns! · (2ri1 + 1) · · · (2rij−1 + 1) · (2rij+1 + 1) · · · (2ris + 1) ≤s! · 3s−1\\nY\\nt∈S\\\\{k}\\nrt\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n17\\npaths in Γ{u,v} that uses the edge {u, v} and the moves mi1, . . . , mij−1, mij+1 . . . , mis. Since\\nall the paths are minimal, they have length at most AM(F) so indeed every path in Γ has\\nthat form.\\n|Γu,v|\\nHπ,f\\nF,M(u, v)\\n≤3AM(F)−1\\nP\\nS∈S\\n\\x10\\n|S|! Q\\nt∈S\\\\{k} rt\\n\\x11\\nf(mij) ·\\n1\\n|Rmij (u)|\\n≤3AM(F)−1 · AM(F)! · |S| · r1r2 . . . rAM(F)\\nf(mij)\\n,\\nwhere we have used the assumption r1 ≥r2 ≥· · · ≥rk. Bounding |S| rigorously from above\\nby 2|M|, the claim follows from Lemma 5.7.\\n□\\nDeﬁnition 5.9. Let F ⊂Zd and M ⊂Zd be ﬁnite sets. The longest ray through F along\\nvectors of M is RF,M := arg max{|RF,m(u)| : m ∈M, u ∈F}.\\nCorollary 5.10. Let (Fi)i∈N be a sequence of ﬁnite sets in Zd and let πi be the uniform\\ndistribution on Fi. Let M ⊂Zd be an augmenting Markov basis for Fi with AM(Fi) ≤\\ndim(Fi) and suppose that (|RFi,M|)dim(Fi))i∈N ∈O(|Fi|)i∈N.\\nThen for any positive mass\\nfunction f : M →[0, 1], there exists ǫ > 0 such that λ(Hπi,f\\nFi,M) ≤1 −ǫ for all i ∈N.\\nProof. This is a straightforward application of Theorem 5.8.\\n□\\nCorollary 5.11. Let P ⊂Zd be a polytope, Fi := (i · P) ∩Zd for i ∈N, and let πi be the\\nuniform distribution on Fi. Suppose that M ⊂Zd is an augmenting Markov basis {Fi : i ∈N}\\nsuch that AM(Fi) ≤dim(P) for all i ∈N. Then for any positive mass function f : M →[0, 1],\\nthere exists ǫ > 0 such that λ(Hπi,f\\nFi,M) ≤1 −ǫ for all i ∈N.\\nProof. Let r := dim(P). We ﬁrst show that (|RFi,M|)i∈N ∈O(i)i∈N. Write M = {m1, . . . , mk}\\nand denote by li := max{|(u + mi · Z) ∩P| : u ∈P} be the length of the longest ray through\\nthe polytope P along mi. It suﬃces to prove that i · (lk + 1) is an upper bound on the\\nlength of any ray along mk through Fi. For that, let u ∈Fi such that u + λmk ∈Fi for\\nsome λ ∈N, then 1\\ni u + λ\\ni mk ∈P and thus ⌊λ\\ni ⌋≤lk, which gives λ ≤i · (lk + 1). With\\nC := max{l1, . . . , lk} + 1 we have |RFi,M| ≤C · i. Ehrhart’s theorem [2, Theorem 3.23]\\ngives (|Fi|)i∈N ∈Ω(ir)i∈N and since |RFi,M| ≤C · i, we have (|RFi,M|r)i∈N ∈O(|Fi|)i∈N. An\\napplication of Corollary 5.10 proves the claim.\\n□\\nExample 5.12. Fix d, r ∈N and let Cd,r := {u ∈Zd : ∥u∥1 ≤r} be the set of integers of the\\nd-dimensional cross-polytope with radius r. The set Md = {e1, . . . , ed} is a Markov basis for\\nCd,r for any r ∈N. We show that Md is an augmenting Markov basis whose augmentation\\nlength is at most d. For that, let u, v ∈Cd,r distinct elements. We claim that there exists\\ni ∈[d] such that xi ̸= vi and ui + (vi −ui) ∈Cd,r. Let S ⊆[d] be the set of indices where u\\nand v diﬀer and let s = r −||u||1. If |S| = 1, then the result is clear so suppose |S| ≥2. If\\nthe result doesn’t hold then for all i ∈S, |vi| −|ui| > s. It follows that\\n∥v∥1 =\\nX\\ni/∈S\\n|ui| +\\nX\\ni∈S\\n|vi| >\\nX\\ni/∈S\\n|ui| +\\nX\\ni∈S\\ns + |ui| = |Suv| · s + ∥u∥1 = (|S| −1) · s + r.\\nBut we assumed that v ∈Cd,r. It follows that for any pair of points u, v in Cd,r, there is a\\nwalk, using the unit vectors as moves, that uses each move at most once. Corollary 5.10 yield\\nthat for any d ∈N, the second largest eigenvalue modulus of the heat-bath random walk on\\nCd,r with uniform as stationary distribution can be strictly bounded away from 1 for r →∞.\\n18\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nThe bound on the second largest eigenvalue in Theorem 5.8 is quite general and can be\\nimproved vastly, provided one has better control over the paths. For example, this can be\\nachieved for hyperrectangles intersected with a halfspace.\\nProposition 5.13. Let a ∈Nd\\n>0, b ∈N, F = {u ∈Nd : aT · u ≤b}, and M := {e1, . . . , ed}.\\nIf π and f are the uniform distributions on F and M respectively, then\\nλ(Hπ,f\\nF,M) ≤1 −|F|\\nd2\\nd\\nY\\ni=1\\nai\\nb .\\nProof. Observe that M is a Markov basis for F since all nodes are connected with 0 ∈F.\\nLet u, v ∈F be distinct. We ﬁrst show that there exists k ∈[d] such that uk ̸= vk and\\nu + (vk −uk)ek ∈F. If u ≤v, the statement trivially holds. Otherwise, there exists k ∈[d]\\nsuch that uk > vk and the vector obtained by replacing the kth coordinate of u by vk remains\\nin F. Now, consider for the following path between u and v: Choose the smallest index\\nk ∈[d] such that uk ̸= vk and such that u + (vk −uk) · ek ∈F and proceed recursively with\\nu + (vk −uk) and v. This gives a path pu,v between u and v of length at most d. Let Γ be\\nthe collection of all these paths. We want to apply Lemma 5.7. Thus, let x ∈F and consider\\nthe edge x →x + c · es. Let us count the paths pu,v that use that edge. Let u, v ∈F and let\\nk1, . . . , kr ∈[d] be distinct indices such that\\nu →u + (vk1 −uk1)ek1 →u + (vk1 −uk1)ek1 + (vk2 −uk2)ek2 →· · · →v\\nrepresents the path pu,v constructed by the upper rule.\\nAssume that pu,v uses the edge\\n{x, x + ces} and let kl = s and (vkl −ukl) = c. In particular,\\nu + (vk1 −uk1)ek1 + · · · + (vkl−1 −ukl−1)ekl−1 = x\\nx + (vkl −ukl)ekl + · · · + (vkr −ukr)ekr = v.\\nWe see that vkt = xkt for all t < l and that ukt = xkt for all t ≥l. In particular, vkl =\\nukl + c = xkl + c is also ﬁxed. The coordinates ukt and vkt are bounded from above by\\nb\\nakt\\nfor all t ∈[r], and hence there can be at most\\n l−1\\nY\\nt=1\\nb\\nakt\\n!\\n·\\n \\nr\\nY\\nt=l+1\\nb\\nakt\\n!\\n.\\nSince k1, . . . , kt are distinct coordinate indices, we have\\n|Γx,x+c·es|\\nHπ,f\\nF,M(x, x + c · es)\\n≤d ·\\nd\\nY\\ni=1\\nb\\nai\\n.\\nLemma 5.7 ﬁnishes the proof.\\n□\\nIn ﬁxed dimension, Proposition 5.13 leads to rapid mixing, but for d →∞, no statement\\ncan be made. In [19], it was shown that the simple walk with an additional halting probability\\non {u ∈Nd : atu ≤b} ∩{0, 1}d has mixing time in O(d4.5+ǫ). For zero-one polytopes, simple\\nand heat-bath walk coincide and we are conﬁdent that a similar statement holds without the\\nrestriction on zero-one polytopes.\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\n19\\nThe heat-bath random walk mixes rapidly when an augmenting Markov basis with a small\\naugmentation length is used.\\nWe think that it is interesting to question how might an\\naugmenting Markov bases be obtained and how their augmentation length can be improved.\\nQuestion 5.14. Let M be an augmenting Markov basis of A. Can we ﬁnd ﬁnitely many\\nmoves m1, . . . , mk such that the augmentation length of M∪{m1, . . . , mk} on FA,b is at most\\ndim(kerZ(A)) for all b ∈NA?\\nReferences\\n1. Stephen Baumert, Archis Ghate, Seksan Kiatsupaibul, Yanfang Shen, Robert L. Smith, and Zelda B.\\nZabinsky, Discrete Hit-and-Run for Sampling Points from Arbitrary Distributions Over Subsets of Integer\\nHyperrectangles, Operations Research 57 (2009), no. 3, 727–739.\\n2. Matthias Beck and Sinai Robins, Computing the Continuous Discretely, Springer, New York, 2007.\\n3. Mary Cryan, Martin Dyer, Leslie Ann Goldberg, Mark Jerrum, and Russell Martin, Rapidly Mixing\\nMarkov Chains for Sampling Contingency Tables with a Constant Number of Rows, SIAM Journal on\\nComputing 36 (2006), no. 1, 247–278.\\n4. Jes´us A. De Loera, Raymond Hemmecke, and Matthias K¨oppe, Algebraic and Geometric Ideas in the\\nTheory of Discrete Optimization, MPS-SIAM Series on Optimization, SIAM, Cambridge, 2013.\\n5. Jes´us A. De Loera, Raymond Hemmecke, and Jon Lee, On Augmentation Algorithms for Linear and\\nInteger-Linear Programming: From Edmonds–Karp to Bland and Beyond, SIAM Journal on Optimization\\n25 (2015), no. 4, 2494–2511.\\n6. Persi Diaconis and Bernd Sturmfels, Algebraic algorithms for sampling from conditional distributions, The\\nAnnals of statistics 26 (1998), no. 1, 363–397.\\n7. Mathias Drton, Bernd Sturmfels, and Seth Sullivant, Lectures on algebraic statistics, Oberwolfach Semi-\\nnars, vol. 39, Springer, Berlin, 2009, A Birkh¨auser book.\\n8. Martin Dyer, Catherine Greenhill, and Mario Ullrich, Structure and eigenvalues of heat-bath Markov\\nchains, Linear Algebra and its Applications 454 (2014), 57–71.\\n9. Giles Gardam, Expander Graphs and Kazhdan’ s Property (T), Bachelor’s thesis, University of Sidney,\\n2012.\\n10. Hisayuki Hara, Akimichi Takemura, and Ruriko Yoshida, On connectivity of ﬁbers with positive marginals\\nin multiple logistic regression, Journal of Multivariate Analysis (2010), 1–26.\\n11. Raymond Hemmecke and Peter N. Malkin, Computing generating sets of lattice ideals and Markov bases\\nof lattices, Journal of Symbolic Computation 44 (2009), no. 10, 1463–1476.\\n12. Roger A. Horn, Matrix Analysis, 2nd ed., Cambridge University Press, New York, 2013.\\n13. Steven S. Kim, Mixing Time of a Rook’s Walk, Undergraduate certiﬁcate paper (2012).\\n14. David A. Levin, Yuval Peres, and Elisabeth L. Wilmer, Markov chains and mixing times, American\\nMathematical Society, Providence, RI, 2009.\\n15. L´aszl´o Lov´asz, Hit-and-run mixes fast, Mathematical Programming 86 (1999), no. 3, 443–461.\\n16. L´aszl´o Lov´asz and Santosh Vempala, Hit-and-Run from a Corner, SIAM Journal on Computing 35 (2006),\\nno. 4, 985–1005.\\n17. Peter N. Malkin, Computing Markov bases, Gr¨obner bases, and extreme rays, Phd thesis, 2007, p. 223.\\n18. Cam McLeman, Peter T. Otto, John Rahmani, and Matthew Sutter, Mixing times for the Rook’s walk\\nvia path coupling, to appear in Involve (2016), 1–12.\\n19. Ben Morris and Alistair Sinclair, Random Walks on Truncated Cubes and Sampling 0-1 Knapsack Solutions,\\nSIAM Journal on Computing 34 (2004), no. 1, 195–226.\\n20. Samu Potka, Higher connectivity of ﬁber graphs of Gr¨obner bases, Journal of Algebraic Statistics 4 (2013),\\nno. 1, 93–107.\\n21. Johannes Rauh and Seth Sullivant, Lifting Markov bases and higher codimension toric ﬁber products,\\nJournal of Symbolic Computation 74 (2016), 276–307.\\n22. Andr´as Seb¨o, Hilbert Bases, Caratheodory’s Theorem and Combinatorial Optimization, (1990), 431–455.\\n20\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\n23. Alistair Sinclair, Improved Bounds for Mixing Rates of Markov Chains and Multicommodity Flow, Com-\\nbinatorics, Probability and Computing 1 (1992), no. 4, 351–370.\\n24. Bernd Sturmfels, Gr¨obner bases and convex polytopes, American Mathematical Society, Providence, R.I.,\\n1996.\\n25. Seth Sullivant, Markov bases of binary graph models, Annals of Combinatorics 7 (2003), 441–466.\\n26. Santosh S. Vempala, Geometric Random Walks: A Survey, MSRI Combinatorial and Computational\\nGeometry 52 (2005), 573–612.\\n27. Tobias Windisch, Rapid mixing and Markov bases, preprint, arXiv:1505.03018 (2015), 1–18.\\nNC State University, Raleigh, NC 27695, USA\\nE-mail address: crstanl2@ncsu.edu\\nOtto-von-Guericke Universit¨at, Magdeburg, Germany\\nE-mail address: windisch@ovgu.de\\n')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d71d8b0f-656b-4946-8e93-19187787fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = WikipediaLoader(query=\"Generative Ai\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb11bb6-c6fd-43c0-8242-a4c10084c38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nSince its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity. The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music. The tradition of creative automations has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\\n\\n\\n=== Academic artificial intelligence ===\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since. Artificial Intelligence research began in the 1950s with works like Computing Machinery and Intelligence (1950) and the 1956 Dartmouth Summer Research Project on AI. Since the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural nets (2014-2019) ===\\n\\nSince its inception, the field of machine learning used both discriminative models and generative models, to model and '),\n",
       " Document(metadata={'title': 'Generative AI pornography', 'summary': 'Generative AI pornography or simply AI pornography refers to digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.', 'source': 'https://en.wikipedia.org/wiki/Generative_AI_pornography'}, page_content='Generative AI pornography or simply AI pornography refers to digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.\\n\\n\\n== History ==\\nThe use of generative AI in the adult industry began in the late 2010s, initially focusing on AI-generated art, music, and visual content. This trend accelerated in 2022 with Stability AI\\'s release of Stable Diffusion (SD), an open-source text-to-image model that enables users to generate images, including NSFW content, from text prompts using the LAION-Aesthetics subset of the LAION-5B dataset. Despite Stability AI\\'s warnings against sexual imagery, SD\\'s public release led to dedicated communities exploring both artistic and explicit content, sparking ethical debates over open-access AI and its use in adult media. By 2020, AI tools had advanced to generate highly realistic adult content, amplifying calls for regulation.\\n\\n\\n=== AI-generated influencers ===\\nOne application of generative AI technology is the creation of AI-generated influencers on platforms such as OnlyFans and Instagram. These AI personas interact with users in ways that can mimic real human engagement, offering an entirely synthetic but convincing experience. While popular among niche audiences, these virtual influencers have prompted discussions about authenticity, consent, and the blurring line between human and AI-generated content, especially in adult entertainment.\\n\\n\\n=== The growth of AI porn sites ===\\nBy 2023, websites dedicated to AI-generated adult content had gained traction, catering to audiences seeking customizable experiences. These platforms allow users to create or view AI-generated pornography tailored to their preferences. These platforms enable users to create or view AI-generated adult content appealing to different preferences through prompts and tags, customizing body type, facial features, and art styles. Tags further refine the output, creating niche and diverse content. Many sites feature extensive image libraries and continuous content feeds, combining personalization with discovery and enhancing user engagement. AI porn sites, therefore, attract those seeking unique or niche experiences, sparking debates on creativity and the ethical boundaries of AI in adult media.\\n\\n\\n== Ethical concerns and misuse ==\\nThe growth of generative AI pornography has also attracted some cause for criticism. AI technology can be exploited to create non-consensual pornographic material, posing risks similar to those seen with deepfake revenge porn and AI-generated NCII (Non-Consensual Intimate Image). A 2023 analysis found that 98% of deepfake videos online are pornographic, with 99% of the victims being women. Some famous celebrities victims of deepfake include Scarlett Johansson, Taylor Swift, and Maisie Williams.\\nOpenAI is exploring whether NSFW content, such as erotica, can be responsibly generated in age-appropriate contexts while maintaining its ban on deepfakes. This proposal has attracted criticism from child safety campaigners who argue it undermines OpenAI\\'s mission to develop \"safe and beneficial\" AI. Additionally, the Internet Watch Foundation has raised concerns about AI being used to generate sexual abuse content involving children.\\n\\n\\n=== AI-generated NCII (AI Undress) ===\\nSeveral US states are taking actions against using deepfake apps and sharing them on the internet. In 2024, San Francisco filed a landmark lawsuit to shut down \"undress\" apps that allow users to generate non-consensual AI nude images, citing violations of state laws. The case aligns with California\\'s recent legislation—SB 926, SB 942, and SB 981—championed by Senators Aisha Wahab and Josh Becker and sig')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad90612-5afc-45ef-8f86-51b11cdedded",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50,chunk_overlap=5)\n",
    "final_doc_splitted = text_splitter.split_documents(text_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f67484-15d3-4bc8-bb4e-c65cc98d8f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='LangChain is an innovative framework designed to'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='to streamline the development of applications'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='that leverage large language models (LLMs). It'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='It offers developers a structured way to'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='to integrate, orchestrate, and chain together'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='various LLM functionalities into comprehensive'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='workflows. By abstracting away many of the'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='the complexities inherent in managing language'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='models, LangChain enables rapid prototyping and'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='and deployment of applications ranging from'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='from chatbots and virtual assistants to'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='to sophisticated text analysis tools.'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='One of the core strengths of LangChain is its'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='its modular design. Developers can build \"chains\"'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='of operations where the output of one component'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='becomes the input for the next, enabling complex,'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='multi-step processing pipelines. This approach'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='not only improves efficiency but also allows for'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='for greater customization and control over how'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='how language models are used within an'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='an application. Additionally, LangChain supports'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='integration with external data sources and APIs,'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='which further enhances its versatility in'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='in real-world applications.'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='Moreover, LangChain fosters an ecosystem where'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='research and development in natural language'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='processing can be translated into practical,'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='user-friendly solutions. As more organizations'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='and developers adopt the framework, it continues'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='to evolve, incorporating cutting-edge techniques'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='and best practices from the AI community. In'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='In essence, LangChain represents a significant'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='step forward in making advanced language model'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='capabilities more accessible and functional for a'),\n",
       " Document(metadata={'source': 'C:/Users/Hp/Desktop/datasets/langchain/docs.txt'}, page_content='a wide array of applications.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_doc_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76c683d8-0839-414e-80ac-a000a5971de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50,chunk_overlap=5)\n",
    "final_doc_splitted = text_splitter.split_documents(text_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33ee88-9f1d-41f3-aac2-4ba7bdd29bab",
   "metadata": {},
   "source": [
    "#LAAMA hosted on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13c52506-92ad-44b3-ab36-4b8869e2f80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_5540\\3979326900.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = (OllamaEmbeddings(model=\"gemma:2b\"))\n"
     ]
    }
   ],
   "source": [
    "embedding = (OllamaEmbeddings(model=\"gemma:2b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e476450-f6ba-4e50-922e-4a1d6ba528ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(base_url='http://localhost:11434', model='gemma:2b', embed_instruction='passage: ', query_instruction='query: ', mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None, show_progress=False, headers=None, model_kwargs=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22fd8d38-2f2b-4cf1-b886-c464c6c8292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = embedding.embed_documents(\n",
    "    [\n",
    "    \"Alpha is the first letter or greek alphabet\",\n",
    "    \"Beta is the 2nd letter or greek alphabet\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a8f7b3-41fb-4876-a1f6-e2fe53c2b81e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2048\n",
      "2048\n",
      "[-2.0256829261779785, -0.07335993647575378, -1.234450101852417, 1.907069444656372, -0.5351279973983765, 0.34967172145843506, -0.7902694940567017, -0.5531549453735352, 1.3176515102386475, -2.4160735607147217, 0.8918792605400085, 0.3512553572654724, 0.9390260577201843, -0.7190391421318054, 0.42039552330970764, 0.15307344496250153, 4.083837985992432, -0.6442542672157288, 0.7847568988800049, -0.11933135241270065, 0.2186925709247589, -1.6152902841567993, -0.26971322298049927, -0.2788480818271637, -1.151474118232727, -1.4006801843643188, -1.384925365447998, -0.21899688243865967, 0.6389219760894775, 1.0425063371658325, -1.0867336988449097, 0.026937689632177353, -0.0841047540307045, -0.769495964050293, -0.8453327417373657, -0.32568323612213135, -2.1498467922210693, 0.7398364543914795, 0.9609220027923584, 0.8050419688224792, 1.1958945989608765, 1.6424683332443237, 1.0752031803131104, -0.5462299585342407, -1.2597534656524658, -2.0870208740234375, 1.0143332481384277, 0.30908656120300293, -2.3866236209869385, 0.6968238353729248, -11.82804012298584, -12.090707778930664, -0.3946940302848816, 0.4529924690723419, -1.7603567838668823, -0.25527986884117126, -0.60860675573349, -0.3812907338142395, -1.0806628465652466, 0.1689511388540268, -0.7253751158714294, 0.6352784633636475, -0.794954776763916, -1.6979949474334717, -2.2908263206481934, -0.9305204749107361, 0.9138922095298767, 0.2291332185268402, 0.4861923158168793, 0.14049391448497772, 1.4823039770126343, -1.007788062095642, -0.8801509737968445, 0.8823859691619873, -1.515657901763916, 1.698392391204834, -0.3769768476486206, 0.229148730635643, 1.7351946830749512, -0.8727487325668335, 0.1290489137172699, -0.2983822226524353, -0.37987709045410156, -2.1298444271087646, 0.40927985310554504, -2.134492874145508, 0.31865569949150085, -0.4868067502975464, 0.7088138461112976, 0.9216189384460449, 0.8419966697692871, 0.4772828221321106, -1.0882116556167603, -0.38324034214019775, 0.0871623158454895, 0.31727227568626404, 1.309666633605957, -0.24951963126659393, 0.06863278895616531, 1.2815109491348267, -2.4838852882385254, 0.2971566319465637, -1.4785734415054321, -0.11604346334934235, -2.932438850402832, 1.940346121788025, 0.22927558422088623, 0.5905609130859375, 6.275557041168213, -0.7607759833335876, -0.6670227646827698, 0.6161061525344849, -0.6257590055465698, -1.2609350681304932, -1.4210137128829956, -0.22709041833877563, -1.4396394491195679, 0.7091761231422424, 0.419270396232605, -0.08822143822908401, -0.3608393371105194, -1.4996020793914795, 0.8192594647407532, 1.2139378786087036, -0.2413441389799118, -0.2582923173904419, -0.3156857192516327, -1.3434630632400513, 1.9033499956130981, 1.3195974826812744, -1.0898385047912598, -1.5973811149597168, 0.059522077441215515, 0.4256497919559479, -0.2900802493095398, -0.4258216321468353, -2.7017199993133545, 2.0955257415771484, 3.1829583644866943, -1.1401607990264893, 0.05078090354800224, 1.45546555519104, -0.408448189496994, -2.58807635307312, -0.057014100253582, -0.7512233853340149, 0.2808675169944763, -2.9125359058380127, 1.3988478183746338, 0.5388049483299255, -1.7181686162948608, -0.04015451297163963, 0.07896818965673447, 0.2969360053539276, -0.7564643025398254, 1.3307390213012695, -3.3054559230804443, -0.5835692286491394, -1.5801538228988647, 0.26699793338775635, 0.4329461455345154, -0.9143774509429932, 0.8912485837936401, -0.8072394728660583, -1.1352529525756836, 1.712977647781372, 0.33891749382019043, -0.5050614476203918, -0.5693368911743164, 0.5122887492179871, 0.2257828712463379, 0.7634663581848145, -0.6056214570999146, -0.3057878017425537, 0.12734945118427277, 1.8272747993469238, 0.3778705298900604, -0.20330950617790222, -1.8208956718444824, -2.351325511932373, 1.9545917510986328, 1.1141939163208008, 0.6627921462059021, -0.39925217628479004, 3.153397560119629, -1.4669264554977417, -0.36104443669319153, 1.2177907228469849, 1.5284966230392456, 0.7820135951042175, -1.625348448753357, -0.681733250617981, -0.5567705035209656, -2.6170156002044678, 1.6634585857391357, -0.4806101322174072, -0.896192729473114, 2.47969913482666, 0.09971945732831955, 0.3228415548801422, -0.802729606628418, 0.009339443407952785, 0.07245787978172302, 1.031379222869873, -0.21403640508651733, 1.8023014068603516, -1.0802396535873413, -1.030186414718628, -0.41894710063934326, -0.9440954923629761, -0.7154953479766846, -0.2626291811466217, 1.309913158416748, -0.04998139292001724, -0.17522583901882172, 1.1785959005355835, -2.0860278606414795, -2.2268383502960205, -0.014890510588884354, -1.722914695739746, 0.1238652691245079, 3.040952444076538, -0.6299533247947693, -0.43878746032714844, -1.1824191808700562, -0.7841139435768127, -0.985917329788208, 4.709057331085205, 1.1948341131210327, -0.9369730949401855, 1.0479146242141724, -1.9209061861038208, -1.2255382537841797, 3.121469497680664, 0.8592888116836548, 0.31572410464286804, -2.0116631984710693, -2.881481170654297, -0.3064787685871124, 0.4682237207889557, -0.5703054070472717, -1.660395860671997, -0.46698880195617676, -1.0928364992141724, -2.0766794681549072, -0.9285885095596313, 0.6744043231010437, 0.519973874092102, -0.4777570962905884, 1.5591567754745483, 1.4436843395233154, -0.20777177810668945, 0.1158427968621254, 2.2150750160217285, 1.9695539474487305, -1.6815071105957031, -1.4351109266281128, -0.5765935182571411, 1.3148880004882812, -1.1594438552856445, -0.23651210963726044, 0.5488430261611938, 0.4221285879611969, 0.5832479000091553, -0.8809143304824829, 1.1442182064056396, -1.4746079444885254, -0.06223384663462639, 0.5201420187950134, -0.5112301111221313, 3.160637378692627, -1.5788522958755493, -1.2591389417648315, -0.43118569254875183, -0.45031100511550903, -2.1827213764190674, 1.7234129905700684, -2.0412845611572266, 0.22032183408737183, 0.588212251663208, 0.7167589068412781, 0.0524807944893837, -0.10253479331731796, -5.185989856719971, -0.6703758835792542, -0.35128745436668396, 1.370234727859497, 0.3122556805610657, 0.5119679570198059, -1.224402904510498, -0.45531976222991943, 0.9298654198646545, 3.364481210708618, 1.2353285551071167, 1.9443289041519165, -1.5877418518066406, 1.5696345567703247, 0.0027264305390417576, -2.171605110168457, -0.13379798829555511, 0.35053738951683044, 1.1066519021987915, -0.08024723082780838, 0.6269858479499817, -2.9022488594055176, -0.5418094992637634, 0.5063391327857971, 0.27260783314704895, -1.0070253610610962, -0.7524278163909912, -0.9485933184623718, 1.5005650520324707, 0.568224310874939, -1.35592520236969, 1.5850661993026733, -0.09121320396661758, 0.8100472688674927, 1.321168303489685, -0.1737089604139328, -0.7490872740745544, 1.2775015830993652, 0.6550137996673584, -0.8461217284202576, -1.3636900186538696, 0.24887150526046753, 1.0342323780059814, -0.5285035967826843, 0.9315956830978394, 1.9550061225891113, 0.6494414806365967, -1.6067906618118286, 0.15947668254375458, -1.4262187480926514, 1.3657968044281006, -1.3578428030014038, -0.511724054813385, 2.1247501373291016, 0.03749017417430878, -0.127958282828331, -0.5648810267448425, 0.4428659975528717, 0.08570847660303116, -0.4410738945007324, -0.05769529938697815, -1.7065353393554688, -0.6854376792907715, -0.29406315088272095, -1.4141993522644043, 0.7271018028259277, -0.41895636916160583, -0.018612993881106377, 0.3111118972301483, -2.504094362258911, -1.3060190677642822, -0.49124419689178467, -0.14566388726234436, -0.22474898397922516, -0.3343169093132019, 1.7979450225830078, 0.5369130373001099, 0.3465428650379181, -0.7263791561126709, -1.8162109851837158, -0.13143596053123474, -0.49246764183044434, -0.7149240970611572, -0.6180118918418884, 2.216716766357422, 0.42600587010383606, 0.8306270241737366, 0.01939661242067814, -0.3377159833908081, 0.6300113797187805, -0.1851932555437088, 0.19393154978752136, -0.39203643798828125, -1.0325262546539307, 0.31501269340515137, 0.4753072261810303, -2.8254125118255615, -1.2621387243270874, -3.873250961303711, 0.3597162365913391, 1.0253490209579468, -0.28827691078186035, -0.9857488870620728, 0.6915491819381714, 0.7145035862922668, -1.5245952606201172, -1.111857295036316, -0.1824081540107727, -0.09125471115112305, -3.3046343326568604, -1.5313668251037598, -0.22470225393772125, 1.2759976387023926, -0.5901885032653809, -0.6547401547431946, -1.8484115600585938, -0.7371959686279297, 0.6866019368171692, 1.3920308351516724, -0.16515077650547028, -1.2924975156784058, 0.2889297902584076, 2.282576084136963, -1.486651062965393, -1.181841492652893, -0.6306819319725037, 0.7409136891365051, -1.816469669342041, -1.1811103820800781, -0.7065987586975098, 0.2912503778934479, -1.054458498954773, -0.2004518359899521, -0.12040603160858154, 0.9350860118865967, -2.0062713623046875, -1.1334102153778076, 1.148651361465454, -0.394322007894516, 2.5109262466430664, 0.7535063624382019, -0.8601551651954651, -0.44329914450645447, 0.3882342278957367, -0.934082567691803, 1.0384068489074707, 1.2496989965438843, 0.6847363114356995, -0.8244595527648926, 0.24398460984230042, -1.138004183769226, 1.5311001539230347, -1.6477917432785034, 0.2635476291179657, 0.9235543012619019, -2.5405662059783936, -1.4198359251022339, 0.11798984557390213, -0.950839638710022, 0.5823291540145874, 2.1832973957061768, -0.7479529976844788, -0.10330189019441605, 2.366631031036377, 0.4358217716217041, -0.8994376063346863, -0.39150580763816833, 1.1498234272003174, -1.4703853130340576, 0.578706681728363, 0.07610318064689636, -0.9509590864181519, 1.7265868186950684, 0.8437314033508301, -1.2480465173721313, -1.1239434480667114, 2.0262982845306396, -0.38666942715644836, -1.8440977334976196, 0.29548245668411255, -0.6177000999450684, -0.0317453034222126, -0.5062804818153381, 1.1678063869476318, 1.337214708328247, 0.7867987751960754, -0.3636343777179718, 1.9979127645492554, 0.9289097189903259, -0.114620141685009, 0.8541014194488525, 1.4350472688674927, 0.8916063904762268, 0.5771074295043945, -0.04911118745803833, -0.19909511506557465, -0.2813953757286072, 0.201257586479187, 1.4240771532058716, -0.9662039279937744, -0.9914764165878296, -1.514426589012146, -0.1079121083021164, -1.6713765859603882, 1.9508342742919922, 1.3789185285568237, -0.801918625831604, 1.3355454206466675, -0.43623554706573486, 1.5967469215393066, 1.8528590202331543, -0.9436792135238647, 1.6045527458190918, -1.9749159812927246, -0.46510472893714905, -0.22858715057373047, -0.1431453377008438, 1.8075908422470093, 1.7817755937576294, 1.1648828983306885, 0.253595769405365, -0.6390768885612488, -1.074081301689148, 1.0474950075149536, 0.39810431003570557, -0.9436315298080444, 0.9832409024238586, 1.0858670473098755, -0.5621910095214844, 0.11180450767278671, 1.8145923614501953, 1.5019190311431885, -1.0175942182540894, -0.24417558312416077, -0.4739260673522949, -0.33976343274116516, 0.0018049716018140316, 0.3889530897140503, -0.48464709520339966, 0.7456839084625244, -0.20151178538799286, 1.690064787864685, -0.06570954620838165, 0.7941587567329407, 2.4147114753723145, 0.4691579043865204, -0.7301499843597412, -0.34609103202819824, 0.9114317893981934, 1.701169729232788, -1.2594751119613647, 1.0896562337875366, -0.25467661023139954, -0.43344345688819885, 0.11553914844989777, -0.7421203255653381, 1.112552285194397, 0.7090743184089661, -0.9538125395774841, -0.48299267888069153, -1.1561380624771118, -0.14805056154727936, 0.2924827039241791, 1.0591599941253662, -1.7069752216339111, -0.5662392377853394, 0.24627816677093506, -0.5122787952423096, 1.0334528684616089, 0.30986878275871277, -0.23734834790229797, 1.1353615522384644, 0.6759592890739441, -0.10745363682508469, 0.10019242018461227, -0.6123411059379578, 0.34427985548973083, -0.13413502275943756, -1.0484402179718018, -0.24820688366889954, 0.23815302550792694, 1.3671703338623047, 0.7586353421211243, -0.49648839235305786, -0.16826321184635162, -1.8004940748214722, 0.6828302145004272, 1.9758923053741455, -0.8307573199272156, -0.6670510172843933, 0.6276161670684814, 0.14660760760307312, 1.4457035064697266, -2.505542755126953, -2.707364320755005, -0.4726448655128479, 0.2993925213813782, 0.1881372034549713, 1.6919090747833252, -1.3304469585418701, -1.6007752418518066, 0.43441852927207947, -0.0939759835600853, 1.2713876962661743, -2.5571985244750977, 0.6466948390007019, 1.6058181524276733, -1.178377389907837, 0.3756418526172638, 1.9009073972702026, 0.5152307152748108, -1.4725781679153442, -0.1666249930858612, -1.184249997138977, 1.3419665098190308, 1.1858049631118774, 0.5229602456092834, 0.5706881880760193, -1.3124098777770996, -1.2286406755447388, 0.6785064935684204, -2.1955952644348145, 0.19194361567497253, -0.6154010891914368, 1.1508835554122925, -1.8624135255813599, -0.6740915179252625, 0.509854793548584, 2.1192026138305664, -2.987818956375122, -0.7085415720939636, 0.7338783144950867, -2.9269790649414062, 3.19762921333313, 3.832278251647949, -0.47294846177101135, 0.31926846504211426, -2.7521796226501465, 0.22258275747299194, -0.21438199281692505, -1.0071579217910767, -2.21413254737854, -0.5812181234359741, 0.24872876703739166, -0.7725129723548889, -0.042538564652204514, -0.941557765007019, -0.6072216033935547, -0.9355713725090027, -1.6669014692306519, 0.3213193714618683, 0.5982951521873474, 0.7996010780334473, 2.340930461883545, 0.6697393655776978, -1.0081602334976196, -0.7037110924720764, 0.3491527736186981, 0.006166878156363964, 1.3206814527511597, -0.9047064185142517, 0.960014820098877, -0.4588904082775116, -0.8921322822570801, 0.18411566317081451, -3.370192766189575, -0.17066092789173126, 0.4609948694705963, -1.298555850982666, 0.8501116633415222, -0.014821083284914494, 1.9317855834960938, 1.7166812419891357, 0.777313768863678, -1.3454159498214722, -1.0342509746551514, -1.4640365839004517, 1.4841195344924927, -1.398207187652588, 0.877066969871521, -0.6620827317237854, 2.729505777359009, 0.28304776549339294, -0.40287548303604126, -0.8183695077896118, 0.38434693217277527, 0.21945923566818237, 0.07074723392724991, -0.9964062571525574, 0.12498446553945541, 0.2129039615392685, -0.008432289585471153, 2.0188565254211426, -0.9170677065849304, 2.0684256553649902, -3.9144093990325928, -0.3293437659740448, 0.47539040446281433, -1.4663119316101074, 1.4404804706573486, 1.1809231042861938, -0.8267402052879333, -0.3411073088645935, 0.5350796580314636, 0.8556288480758667, 0.035306643694639206, -1.06201171875, 1.1298056840896606, 0.06608152389526367, -0.5166234374046326, 0.4664978086948395, 1.6959222555160522, 0.2733963131904602, 0.08864949643611908, -0.3008449971675873, 1.0422765016555786, 0.2359529584646225, -3.019697427749634, -0.24670399725437164, -0.3880682587623596, 2.407327890396118, 0.4360915422439575, 0.5418108701705933, 0.09691113978624344, 1.1180311441421509, 1.06113600730896, -0.42233213782310486, -0.8154926300048828, 0.5033292174339294, -1.55971360206604, 2.098529577255249, -1.4314631223678589, 0.6580256819725037, 0.09801621735095978, 0.7063619494438171, 0.4880865216255188, 1.0826566219329834, -1.085347056388855, 1.051287293434143, 0.0032120882533490658, 0.250421404838562, -0.9322740435600281, -0.8062782883644104, -0.79502272605896, 1.4682049751281738, -0.09737017005681992, 0.6403322815895081, 0.8288334608078003, 0.7405336499214172, 0.5394204258918762, -2.9371492862701416, -1.2037347555160522, 0.3226892352104187, -3.605311870574951, -0.36728182435035706, 0.3835691511631012, -0.6312805414199829, 1.7055684328079224, -1.00033700466156, 0.1551349014043808, 0.8611088395118713, 0.577910304069519, -0.8320462107658386, -0.6735988855361938, 0.45565950870513916, -0.5901868939399719, 0.40653425455093384, 0.34758150577545166, 0.5901609063148499, -2.65714430809021, -6.436093330383301, -0.8186836838722229, -0.5764727592468262, -0.3112501800060272, -0.43821367621421814, 0.8681057095527649, 0.3081490397453308, 1.5661832094192505, 1.1583157777786255, 0.35537227988243103, 0.15444932878017426, -0.024563603103160858, 0.6338713765144348, 0.7190454006195068, 0.6408055424690247, -1.1572610139846802, -1.3691823482513428, -0.9265871047973633, -2.00471830368042, -0.7366155982017517, -0.509442150592804, 0.39400580525398254, 0.9460378289222717, -0.12455195933580399, 0.9337095022201538, 3.1262731552124023, -0.5148043632507324, 1.4746270179748535, -0.12755568325519562, -0.1193050742149353, -0.8263359069824219, 0.7475486397743225, -0.2403632551431656, 0.4177626371383667, 1.189491868019104, -0.5033020973205566, -0.9367401599884033, -1.1259444952011108, 0.9647233486175537, 0.4393065869808197, 1.512891411781311, 0.8357645869255066, 0.3110291063785553, -0.7440546751022339, -1.0859493017196655, 2.563152313232422, -0.12935872375965118, -0.853285551071167, 0.43111225962638855, 2.5206046104431152, 0.205608069896698, 2.1391332149505615, 0.7697327136993408, -0.5302699208259583, 0.2911357283592224, 0.09734422713518143, -0.5651424527168274, 0.39645326137542725, -2.402818202972412, 1.1969345808029175, -1.1217246055603027, 1.654140591621399, 1.0514343976974487, -0.09463174641132355, -1.6666274070739746, 0.9794257283210754, -1.9638289213180542, -1.3116105794906616, -0.5599349737167358, -1.2589287757873535, -6.871631622314453, -1.4374654293060303, -0.8920268416404724, -0.8973302841186523, -0.4400824010372162, 1.6390904188156128, -0.3224089443683624, -1.7228232622146606, 0.6995082497596741, 1.3146061897277832, 0.08879189938306808, -0.4977053105831146, -0.08571352064609528, -0.1751430183649063, 1.880579948425293, -1.5137901306152344, 0.7450949549674988, -1.494490623474121, -1.2404502630233765, -0.9664713740348816, -0.7038530111312866, -0.8704848289489746, 1.0680140256881714, -2.260321617126465, -1.3396880626678467, 0.5162704586982727, -0.5512513518333435, 0.5068458318710327, 1.116891860961914, 2.136998176574707, -0.6751938462257385, 0.21328192949295044, -1.3234450817108154, 0.5349435806274414, 1.5391466617584229, -2.7624127864837646, -1.1645747423171997, -2.1392245292663574, 0.30050837993621826, -0.8512227535247803, -0.12698210775852203, -0.7761926054954529, -0.132367342710495, -1.053199291229248, 0.6019768714904785, -0.9053325057029724, 0.2584477365016937, -0.013005736283957958, 2.5952141284942627, 2.427285671234131, 1.0448106527328491, -1.1917012929916382, -0.0978822335600853, -3.0112221240997314, 1.9996891021728516, 1.107348918914795, -1.5039427280426025, 0.1944861263036728, -0.8024409413337708, -1.0877201557159424, -0.08047589659690857, -2.065250873565674, -0.15311263501644135, -0.7718074321746826, 0.8900348544120789, -1.098218560218811, -0.7815905213356018, 1.125338077545166, 1.6155400276184082, -0.4568372666835785, 0.06488590687513351, 1.2686277627944946, -0.26102155447006226, 0.9357998967170715, -0.4191818833351135, -0.14351339638233185, -0.49111223220825195, -0.5519365668296814, 2.1094255447387695, -3.2618889808654785, 0.4912668466567993, 0.1989159733057022, 1.49789559841156, 0.6854943037033081, 2.236426830291748, -2.5874598026275635, -0.36843734979629517, 0.5097883343696594, 0.5319554805755615, -0.1824372112751007, 0.2463766187429428, 1.207439661026001, 0.891055703163147, 0.15162765979766846, -1.0105570554733276, -1.0816861391067505, -0.5049890875816345, 2.1110997200012207, 0.053131941705942154, -0.18800316751003265, 1.6200059652328491, 3.747488498687744, -2.742274522781372, -0.8251659274101257, 14.578057289123535, 1.2811557054519653, -1.7760944366455078, 0.46242403984069824, 0.15641623735427856, 0.3854200541973114, -0.20979347825050354, -0.06737630814313889, -0.029747413471341133, -0.9150132536888123, -2.052243232727051, 1.008028507232666, -3.8066556453704834, -4.034402847290039, -0.4800465404987335, 3.4852869510650635, -1.3117825984954834, -0.9601883292198181, -1.0941932201385498, -1.3415905237197876, -0.1601262092590332, -2.489424228668213, -0.21562469005584717, 0.6536045670509338, -1.663394808769226, 1.4662505388259888, 1.0221073627471924, 0.6147229075431824, 1.9183613061904907, -0.36887380480766296, -1.0332623720169067, -2.188007354736328, -0.8929361701011658, 1.5018589496612549, -0.034747861325740814, 1.0877727270126343, -0.6557269096374512, 1.4485102891921997, 2.448978900909424, 0.06702463328838348, -0.6539682149887085, -0.07009957730770111, -0.05219585448503494, 0.6340094208717346, 1.1048091650009155, -0.9518622756004333, 0.07677178084850311, 2.210930109024048, 0.5216578245162964, 0.8174595236778259, 0.7655859589576721, -0.06613561511039734, -1.467320442199707, 0.12428181618452072, 10.610054969787598, -2.8855268955230713, -0.05197932571172714, -0.6332815885543823, -0.8882070779800415, 0.5278123021125793, -1.6138792037963867, -1.5313658714294434, 0.6793341040611267, -0.49014580249786377, -0.07501830905675888, 0.9758864641189575, -1.8770215511322021, -0.9232348203659058, -0.6132965087890625, 0.7031303644180298, -0.48973348736763, 0.5045415163040161, -0.1703106313943863, 0.5952643752098083, -2.2823965549468994, -0.735141396522522, -0.09632889181375504, -2.27787709236145, -0.30266645550727844, 0.6053137183189392, -0.10946578532457352, 1.7931379079818726, -2.6011030673980713, -0.3536675274372101, 1.8971089124679565, -0.4222877323627472, 0.025423981249332428, -3.0569233894348145, 0.29016512632369995, -1.384506106376648, -0.13013556599617004, -1.5570554733276367, -0.2382885366678238, -0.4532976746559143, 0.238673135638237, -1.9141961336135864, -0.3527863919734955, 0.916958212852478, 2.1300108432769775, -0.5167804956436157, -0.9948825836181641, 0.03620787337422371, 2.062103748321533, 0.22629530727863312, 1.1410613059997559, 1.5420092344284058, -0.9833821058273315, -0.6316975355148315, -0.2507894039154053, -0.1342758983373642, -0.6757894158363342, -0.9707358479499817, 0.8820459246635437, -0.6941595673561096, -1.716214656829834, -0.24381037056446075, -0.5636364221572876, 0.46711739897727966, 0.8479929566383362, -0.44334280490875244, -1.2895276546478271, 2.343743324279785, 0.13580502569675446, -1.643615484237671, -0.9797301888465881, 2.2960524559020996, -0.7065399289131165, -0.9361563920974731, -1.5936365127563477, 0.6697160601615906, 0.782436192035675, 0.9115812182426453, 0.2176092565059662, 0.13280922174453735, -0.48953863978385925, -1.6936006546020508, 0.01736419089138508, -0.3705241084098816, 1.577876329421997, -2.0632431507110596, 0.016729479655623436, 1.2520368099212646, -0.3704008162021637, 1.0629380941390991, -0.27148669958114624, -1.9542815685272217, 0.8643856048583984, -0.5680639743804932, -1.6790680885314941, -0.5239013433456421, 0.9014508128166199, -1.207041621208191, 0.09418458491563797, -0.2689789831638336, 0.48203495144844055, -0.5268283486366272, 0.49973639845848083, -0.6777653694152832, 0.5040822625160217, 0.2561424970626831, -0.40917935967445374, 0.9141029715538025, -0.5899629592895508, 1.0983848571777344, -2.860351324081421, 0.08451998233795166, 0.37264567613601685, 1.2935926914215088, 0.790333092212677, -0.5864131450653076, -2.213710069656372, 0.07264290750026703, 0.2601383328437805, 0.40099820494651794, 0.9699907302856445, -0.4587272107601166, -0.9317688345909119, -0.23788490891456604, -0.5109345316886902, -0.5898206233978271, 0.5657311677932739, -0.45369914174079895, -0.2972431480884552, 2.6753182411193848, 0.04978995397686958, 0.5265488624572754, 0.3299251198768616, -0.506671130657196, 0.6874656677246094, -0.3689051866531372, -0.6458044052124023, 1.9510596990585327, -0.055188994854688644, -6.456430912017822, -0.7288035750389099, -0.13193753361701965, -0.8252565264701843, -0.41551387310028076, -0.930425226688385, 3.14167857170105, 0.6246269345283508, -0.03443698585033417, 0.4976097047328949, 0.27690374851226807, -1.3096109628677368, -0.09325490146875381, -2.129796266555786, 1.1151000261306763, 1.7135913372039795, 0.11445602774620056, -1.9485236406326294, 0.9378690123558044, -1.0966001749038696, 0.8115531802177429, 0.1104915663599968, -1.3483684062957764, 0.9995657205581665, -1.177551031112671, -0.9947054386138916, 0.9154002070426941, 2.7441959381103516, -0.42196783423423767, 0.7288245558738708, 1.5328845977783203, -1.4677307605743408, 1.1262426376342773, 0.29711395502090454, -2.3111228942871094, -0.5546106100082397, 0.4602653384208679, 1.1272326707839966, -1.646764874458313, -1.1601507663726807, 0.04203182831406593, 0.6140263080596924, -4.158249855041504, 0.2469443529844284, -0.38153815269470215, -0.06264452636241913, -1.1845054626464844, -2.0730795860290527, -0.1733720600605011, 1.8204671144485474, 1.069985032081604, 2.455165147781372, 1.23668372631073, -2.3847737312316895, 0.06550958007574081, 0.7892739176750183, 1.3631654977798462, 0.052032314240932465, 1.2227998971939087, 1.5669595003128052, -1.596051573753357, -0.2810371220111847, -0.0607890821993351, 1.3892229795455933, -0.2552424967288971, -0.15916657447814941, -1.1555283069610596, 0.35703685879707336, 0.9280915856361389, 0.3453911244869232, 6.815572261810303, -0.9863007664680481, -0.9693811535835266, 1.0195896625518799, 0.7521889209747314, 0.6431890726089478, -1.1129006147384644, 0.1726829558610916, -0.7810552716255188, 1.295048713684082, 2.0263452529907227, -0.747607409954071, -0.12140499800443649, 0.791155993938446, -0.3481060564517975, 0.2432674616575241, 0.7400683760643005, -0.7894647717475891, 1.0899862051010132, 0.2509016990661621, 0.5970991849899292, -1.5938632488250732, -0.16076692938804626, 2.0245778560638428, 1.4539358615875244, 0.705675482749939, 0.1629941612482071, -0.05874593183398247, 2.326112985610962, 0.9560766816139221, -0.07457806915044785, -0.703183650970459, -0.5407535433769226, 0.0675375834107399, 0.7999870181083679, 1.9260188341140747, -1.0639472007751465, -1.8927879333496094, 0.5191115736961365, -1.237571120262146, 0.21626664698123932, -0.37446776032447815, -0.4678540527820587, 1.4622645378112793, -1.5588128566741943, 1.1242468357086182, 1.5164539813995361, -1.964164137840271, 0.4773326516151428, -0.7451353073120117, 0.013722076080739498, -2.5904431343078613, 1.3305375576019287, -0.33073529601097107, -0.5887136459350586, -0.5938513875007629, -0.04123029485344887, -1.0601646900177002, -1.525672435760498, -1.2663707733154297, -0.6626893281936646, 2.0382487773895264, 0.8867428302764893, -1.5989710092544556, -1.2210278511047363, 1.155458927154541, 2.140596628189087, -0.8103610873222351, 0.27479252219200134, -1.0608479976654053, 0.07904055714607239, -1.22706937789917, -1.1920374631881714, 2.3937950134277344, -1.0092371702194214, -0.5007401704788208, 2.805441379547119, 1.3085699081420898, -0.5148434042930603, 0.5021352767944336, -1.0908669233322144, 0.15461793541908264, 0.9341366291046143, 0.9198473691940308, 1.288679838180542, 0.14389394223690033, -0.1530608832836151, 0.7524363398551941, -1.7158879041671753, -1.614255666732788, 0.43511122465133667, 0.4254099130630493, 0.36849379539489746, -0.15900789201259613, 0.8314365744590759, 0.3279059827327728, -1.8413220643997192, -0.1523839384317398, -0.24689219892024994, -0.3080527186393738, -0.7992760539054871, 5.744130611419678, 0.018858077004551888, -0.4731311500072479, -0.8354912400245667, 0.2077937126159668, 0.1577102243900299, -0.4660484194755554, -0.6544123888015747, -1.890494704246521, -0.7640990018844604, -0.9164747595787048, -1.592694640159607, 0.01795061305165291, 0.14110501110553741, -2.0611155033111572, 1.7272549867630005, -1.0924443006515503, -0.2848753333091736, -0.41331446170806885, 1.6427903175354004, -0.5206335186958313, 1.676135540008545, -0.3377431631088257, 0.7736722826957703, -0.9087278246879578, 1.4938493967056274, -0.7001076936721802, 1.661845088005066, -2.2912254333496094, -0.8879010677337646, -1.3593575954437256, 0.7781736254692078, -0.6089574694633484, 1.470390796661377, -1.4512982368469238, -1.0924017429351807, -0.5693399906158447, 0.8473906517028809, 0.00798052828758955, 0.5963444709777832, 0.9635728597640991, 0.051983218640089035, 2.0576162338256836, -0.5142577290534973, 0.05565302446484566, -0.6026490926742554, -1.771166443824768, 2.011848211288452, -0.3918018043041229, -1.7389397621154785, -1.4240427017211914, -1.1264389753341675, -0.4329319894313812, -1.4368952512741089, 0.10787101089954376, -0.24634288251399994, -1.0976688861846924, 0.3194105327129364, -0.7650604248046875, -0.906758725643158, 1.4737019538879395, 0.9759427309036255, -0.9641667008399963, -1.593523621559143, -0.43980613350868225, 0.39060065150260925, -0.5933228135108948, -0.655636191368103, 0.7692147493362427, -0.6181921362876892, -1.759423851966858, 0.2395780235528946, 0.7797991633415222, -1.60399329662323, 1.1881951093673706, 1.28963303565979, -0.04801154509186745, 0.1119978129863739, 0.7590906023979187, -0.26903489232063293, 0.23434601724147797, 1.464078664779663, -1.6778912544250488, 1.1028062105178833, -0.7537931799888611, 1.6985207796096802, -0.047674134373664856, -0.9046825766563416, 1.792340636253357, 6.218271732330322, 0.000715972448233515, 0.59351646900177, -1.2863373756408691, 1.1016358137130737, 0.5293540358543396, 0.3944477438926697, 1.8491488695144653, -3.1135823726654053, 1.6772657632827759, -2.037235975265503, 1.9320752620697021, -0.14211082458496094, 1.189315915107727, 1.528639554977417, -1.6155349016189575, -1.4594038724899292, -0.07488594204187393, 1.628331184387207, -2.3668336868286133, -0.2825882136821747, 0.42174971103668213, -1.1280287504196167, -1.1861529350280762, 0.25932157039642334, -0.7497468590736389, 1.4746160507202148, -0.836318850517273, -1.2813588380813599, -0.08738059550523758, -0.5175392031669617, 0.24265383183956146, 0.6546084880828857, -2.178295850753784, 0.6429453492164612, -2.479787826538086, 0.5375832319259644, -2.061882972717285, 1.6103439331054688, 1.003647804260254, -0.436381459236145, -0.3279421329498291, 0.22551178932189941, 0.5456213355064392, 1.145060658454895, 1.7316274642944336, 0.3657035827636719, 0.44294604659080505, -0.6492511034011841, -0.4439871907234192, 0.44915249943733215, -0.015423336997628212, -0.6211000680923462, -2.0735199451446533, -1.0106909275054932, 2.184535026550293, -0.12212846428155899, 1.884230375289917, -0.13786526024341583, 1.3002914190292358, -1.4928418397903442, -0.287813276052475, 0.4667524993419647, -0.5078648924827576, -1.3368722200393677, -6.520045280456543, -1.3327488899230957, 1.2593636512756348, 0.7522687911987305, -0.5904470682144165, -1.2069005966186523, 0.3908673822879791, 0.4996461570262909, -0.5493856072425842, 0.118613600730896, 1.8318099975585938, 0.7313708662986755, 0.342875599861145, 1.0981863737106323, -0.3918587267398834, -2.3927178382873535, 1.12199866771698, -0.6727747321128845, 0.5631338357925415, -1.4332730770111084, 2.328383684158325, 0.4318222105503082, 0.33877235651016235, -0.1984294056892395, -2.07399320602417, -1.3925033807754517, 1.091289758682251, 0.2850649356842041, -2.7867887020111084, -0.21796837449073792, -0.2725766599178314, 0.7224108576774597, -0.06701100617647171, -0.5606364011764526, 0.24443376064300537, 0.5631470680236816, 0.7347000241279602, -1.8171839714050293, 1.4299873113632202, -2.123654842376709, -0.010997806675732136, 0.21616369485855103, 1.1553460359573364, -0.08812019228935242, 0.25490131974220276, -0.5853243470191956, 1.7905573844909668, 1.5376548767089844, 0.42543166875839233, 0.2590986490249634, -0.34472283720970154, -0.39257025718688965, 0.265419065952301, 0.6158533096313477, -14.574135780334473, -1.1821253299713135, 1.5310251712799072, -1.026666283607483, 0.07241111248731613, 1.293540596961975, -0.5794902443885803, 0.261340469121933, 0.2497396469116211, -1.4332338571548462, 0.21082130074501038, 1.8669439554214478, 0.785397469997406, 1.0922902822494507, 0.1245308592915535, 0.7820361852645874, -0.24583066999912262, -0.463979035615921, 1.1175793409347534, 1.9118797779083252, -0.9059464931488037, 0.22623860836029053, -0.64057856798172, 0.43897438049316406, 2.398198366165161, -0.0724988728761673, -0.043444033712148666, -1.4474531412124634, -0.44143497943878174, 1.7344920635223389, -0.6020676493644714, -1.1375019550323486, -4.126755237579346, -1.4837210178375244, -1.3613834381103516, -0.12580043077468872, -0.4110065698623657, -0.7565150260925293, -0.7252300977706909, 0.9107305407524109, -0.19992847740650177, -1.0690011978149414, 1.9947060346603394, -0.587273120880127, -0.12471452355384827, -3.5015981197357178, 1.6616489887237549, -0.9310452342033386, -0.7218071222305298, -2.849043130874634, 0.7658925652503967, -0.5661001801490784, 2.7877817153930664, 0.8322883248329163, 0.4587394595146179, -0.9077851176261902, -1.9366365671157837, -0.7772713899612427, 0.8946520686149597, 0.7747242450714111, -2.014292001724243, 0.8943930864334106, 0.5886477828025818, -0.804768979549408, 1.2300275564193726, -1.4237325191497803, -2.2316689491271973, 0.6325424909591675, 0.49217841029167175, 0.14887338876724243, -1.5933706760406494, -0.41318219900131226, 0.743971049785614, 1.4594522714614868, -0.312500536441803, -1.2516322135925293, -2.936027765274048, 5.286524295806885, 5.822853088378906, 1.1275030374526978, -0.49452462792396545, -1.3684496879577637, 0.3893919587135315, 0.2699665129184723, 0.813031792640686, 1.2586357593536377, 1.087768316268921, 0.43346840143203735, -0.030982917174696922, 0.4558980464935303, -0.25491246581077576, -1.288486123085022, -0.5161766409873962, 0.7836851477622986, -1.8242000341415405, 0.7728981375694275, 0.2625650465488434, 2.8069915771484375, -0.6734672784805298, 1.4606610536575317, 1.1484684944152832, 1.1905922889709473, 0.0707145482301712, 1.467831015586853, -1.2224904298782349, 1.2451047897338867, -0.2179475873708725, 0.5402091145515442, 0.06553898751735687, -0.6655299663543701, 1.2176330089569092, -0.40047168731689453, -0.6457154154777527, 0.40018779039382935, 0.32789596915245056, 0.2572079300880432, 0.7982143759727478, -1.1705855131149292, -0.2634711265563965, 1.0992321968078613, -0.8820505142211914, 0.44894927740097046, 0.42886778712272644, 0.7189621925354004, -1.49238920211792, 0.45932409167289734, 1.1181892156600952, 2.423046112060547, 2.9901363849639893, -2.5641865730285645, -1.639783263206482, -0.2474256306886673, -1.273759365081787, -1.5310617685317993, 0.26165682077407837, -1.9093711376190186, -1.2903591394424438, -0.4830566942691803, -0.42289450764656067, -0.7341325283050537, -0.6814305782318115, -1.1868836879730225, -0.34153756499290466, 0.3374118506908417, -0.5224094390869141, -1.6820415258407593, -5.548154830932617, 0.18701840937137604, -1.0645922422409058, -2.2423014640808105, 0.002128883730620146, 1.8909157514572144, -0.9827587604522705, 0.557652473449707, 0.8024339079856873, -0.4170074462890625, -1.8149521350860596, 0.27588707208633423, 0.7154820561408997, -0.4794890284538269, 0.11666017770767212, 1.7486401796340942, 0.32890835404396057, -0.045902740210294724, 1.221558690071106, -0.6239901781082153, -2.883547067642212, -0.22912108898162842, -0.9927895069122314, 0.10703103989362717, -0.18067574501037598, -2.0453941822052, 0.3443867564201355, 2.1942145824432373, 0.2385396659374237, 0.3729013502597809, -0.05173255503177643, 1.0249451398849487, 1.119374394416809, 0.21690888702869415, 0.43312180042266846, 0.30074915289878845, -0.7572364211082458, 0.27391478419303894, 0.7741960883140564, -0.3542947769165039, 1.0747802257537842, 0.3413377106189728, -1.0585235357284546, 0.1627037525177002, -0.13743990659713745, -0.11001645028591156, -1.350925087928772, 0.5706453323364258, -0.3881774842739105, 0.32602718472480774, 0.5034139156341553, -1.1390715837478638, 2.1841111183166504, 0.2995337247848511, 7.070826053619385, 0.4281699061393738, 1.0278886556625366, 0.2829720675945282, 8.091974258422852, 0.9913384914398193, 1.4967474937438965, -1.7626762390136719, 1.549141526222229, 0.43819117546081543, 0.4862166941165924, -1.653620719909668, 0.6819620132446289, -1.5389504432678223, -9.693796157836914, -1.514528512954712, 0.38234594464302063, 1.397554874420166, 0.32827261090278625, -0.8544655442237854, -1.1491210460662842, 0.5478627681732178, -0.05353575944900513, 0.3249528408050537, -1.5552663803100586, 0.1937800645828247, -1.0141938924789429, -0.7024098038673401, -0.6752238273620605, -0.7335846424102783, 1.1559754610061646, -0.33243557810783386, 1.6687278747558594, -0.8470374345779419, -1.5682332515716553, 0.09809710830450058, 1.2975726127624512, -0.06996775418519974, -0.6205227971076965, 1.1324543952941895, -1.6594654321670532, -1.3457368612289429, -0.678935170173645, 0.8650035858154297, -0.5571631789207458, -0.699984073638916, -2.1881661415100098, 0.7294178605079651, 0.766108512878418, -2.3786983489990234, -0.026225432753562927, -1.1393321752548218, -0.6779369711875916, -0.9372878074645996, 0.051241133362054825, -0.06844045966863632, 0.3326284885406494, -2.3350658416748047, 0.4199586808681488, 0.4398691654205322, -1.5094242095947266, -0.7506284713745117, -0.4649510383605957, -0.6594445109367371, 0.5197434425354004, 0.21711140871047974, -0.3183627128601074, -1.2377359867095947, 0.2643918991088867, 0.7909718155860901, 1.0372893810272217, 0.8843894600868225, -0.0696183443069458, 0.23225991427898407, 0.06026465445756912, 1.7533336877822876, -0.059970028698444366, 0.17078442871570587, 0.11362496018409729, 1.0769355297088623, 0.08022386580705643, 0.21747548878192902, 0.758057713508606, 0.0918368324637413, 1.2706201076507568, 2.636531352996826, 2.0980124473571777, -1.0449275970458984, -0.8130415678024292, -2.430614709854126, -1.1684541702270508, 9.941117286682129, -2.2319083213806152, 1.3654924631118774, 1.6989084482192993, -0.022398337721824646, 0.17601566016674042, -0.03789355605840683, 0.18259353935718536, -1.2116106748580933, -0.4810929000377655, -0.1210751011967659, -0.9186888933181763, 1.0806852579116821, -0.2650217115879059, 0.04219754785299301, 0.45228123664855957, 1.4238530397415161, -0.41092538833618164, -0.0429423563182354, 0.8712244033813477, -1.2918401956558228, 0.37016600370407104, -1.1588985919952393, -1.195538878440857, -0.5625357627868652, 1.8267039060592651, 0.07366810739040375, 0.31301963329315186, 1.5921624898910522, 0.40610259771347046, -0.8399584889411926, -1.3938775062561035, 2.191131353378296, 0.06093548983335495, -0.3328045904636383, -0.7378110885620117, -1.4733760356903076, -0.5349379777908325, -2.2949836254119873, -1.9304243326187134, -1.6220433712005615, 1.2054036855697632, -0.6690855026245117, 0.1480533331632614, -0.6204301118850708, -0.45934247970581055, -0.9992931485176086, -1.3085914850234985, -2.8120601177215576, 2.5796666145324707, -2.3212890625, 1.2207367420196533, 0.6192991137504578, 0.7405321002006531, 0.42176365852355957, 0.9187637567520142, -0.8551284074783325, 1.262393593788147, -1.1480653285980225, 2.0733017921447754, 0.4460793137550354, -0.17219841480255127, 4.274281024932861, 2.695549964904785, -0.08454146236181259, 0.9647155404090881, 2.7680883407592773, 0.24762623012065887, -0.18535147607326508, 0.5753875374794006, 1.6019221544265747, -0.02254575677216053, -0.6490179300308228, -0.4954487085342407, 3.045717716217041, -1.0776387453079224, 1.084801197052002, -0.6051670908927917, 1.6733273267745972, 0.3931386470794678, 0.682165265083313, 1.082650065422058, 1.9443718194961548, -0.2176453173160553, -1.1164045333862305, -2.5111141204833984, -1.5137656927108765, -0.07321448624134064, 0.6412885189056396, 1.9905169010162354, -0.3486166298389435, -1.036660075187683, 0.8662025332450867, -1.3961869478225708, -2.317479133605957, -2.7879016399383545, 1.8479293584823608, 1.743067979812622, -0.9551123380661011, 0.2187163233757019, 0.9566499590873718, -2.149733543395996, 0.8392351269721985, 0.014448918402194977, 0.34452149271965027, -0.9428128600120544, -2.1353049278259277, 0.7607051730155945, 0.4055325984954834, -0.27223581075668335, -0.6706089377403259, 1.65200936794281, -1.4659737348556519, -0.7658683657646179, 0.7876964807510376, -0.8584845662117004, -2.2206335067749023, 1.3310532569885254, -0.3480950593948364, -0.5656524300575256, -0.7016943097114563, 0.26154106855392456, -0.10201175510883331, 1.0782665014266968, 3.3821427822113037, 1.1240416765213013, 2.1241235733032227, 0.8487964272499084, -1.1326160430908203, -0.27732643485069275, 1.535037875175476, 0.006356318015605211, 0.7726368308067322, -0.3770255446434021, -0.13725456595420837, -2.808875560760498, 1.044602632522583, 0.4821740388870239, 0.7309536337852478, -0.5369028449058533, -0.8409985899925232, 0.8070472478866577, 0.7819579839706421, -1.3498238325119019, 0.960271418094635, 3.558595657348633, -2.1876792907714844, 1.6624689102172852, 0.19091713428497314, -1.108205795288086, -0.3206712007522583, 1.2015477418899536, -0.26783299446105957, 0.1435195952653885, 0.4211059510707855, 1.327555775642395, 1.2062485218048096, -1.3303872346878052, -0.09547383338212967, 0.704088568687439, -0.2729741334915161, -0.6093317866325378, 0.6431226134300232, 0.07244053483009338, -1.8845847845077515, -1.0141422748565674, 1.0307443141937256, -1.055906891822815, -0.5606027841567993, 20.936603546142578, -1.2133859395980835, -0.5780113935470581, -1.140661358833313, 1.0515793561935425, -0.7040820717811584, 0.7166805267333984, 0.2271702140569687, 1.5468393564224243, 2.570716142654419, 1.0548633337020874, 0.45112112164497375, 0.03748425841331482, -0.08235877007246017, -0.8718515038490295, -1.0224586725234985, -0.5643816590309143, -0.00027644081274047494, 1.2013496160507202, -0.5174509882926941, 0.02317962981760502, 0.5859731435775757, 0.9603342413902283, -0.4581032991409302, 0.36355698108673096, 1.8614650964736938, 0.762951672077179, -1.1880943775177002, 2.5725648403167725, 1.6828653812408447, 2.4062697887420654, -0.19823384284973145, 0.6533517837524414, 1.453217625617981, 0.6652944087982178, -1.1790192127227783, 2.313783645629883, -0.29431191086769104, 0.7385216951370239, -0.8191202282905579, -1.3766876459121704, -0.0987795740365982, -0.7309651970863342, -0.6651505827903748, 1.9214214086532593, -1.3594794273376465, -1.221828818321228, -0.9410501718521118, 0.2119990438222885, 1.1896859407424927, -0.6115767359733582, -1.4807504415512085, -0.03853058069944382, 0.7044656872749329, -0.8021504282951355, 0.36633291840553284, -3.4592947959899902, 1.302304744720459, 0.8460246324539185, 0.5250709056854248, -5.96072244644165, -1.3547500371932983, 1.4136383533477783, -1.0338608026504517, 0.24951738119125366, 0.28047290444374084, -1.1057329177856445, 1.7593443393707275, -0.114999920129776, -1.012186050415039, 0.11090690642595291, -0.06723369657993317, -0.7572226524353027, 0.533165693283081, 3.4481277465820312, 1.5945391654968262, -0.15030553936958313, 1.3315422534942627, 0.8378475308418274, -0.2933260500431061, 0.8599915504455566, -0.5061116814613342, -0.8731500506401062, -1.6943926811218262, -0.26768600940704346, 6.032061576843262, 1.595802903175354, -0.41294750571250916, -2.090794324874878]\n"
     ]
    }
   ],
   "source": [
    "print(len(r1))\n",
    "print(len(r1[0]))\n",
    "print(len(r1[1]))\n",
    "\n",
    "print(r1[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a47b95-9b08-4239-9f1f-bbd9d5e68663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 510, which is longer than the specified 50\n",
      "Created a chunk of size 525, which is longer than the specified 50\n",
      "Created a chunk of size 495, which is longer than the specified 50\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"C:/Users/Hp/Desktop/datasets/langchain/docs.txt\")\n",
    "document = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 50, chunk_overlap = 10)\n",
    "docs = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fef40-8cc6-40bf-8bd0-1b3489fc6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cda54c-d501-4fe8-9619-5040b8dbbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIASS DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a0aaef-baf2-4d15-a5f9-773370e51a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_17624\\1005239325.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = (OllamaEmbeddings(model=\"gemma:2b\"))\n"
     ]
    }
   ],
   "source": [
    "embedding = (OllamaEmbeddings(model=\"gemma:2b\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be089964-024f-494c-87d8-499c68e0311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs,embedding)\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543f353-f879-4793-b298-978453dda1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who invented langchain?\"\n",
    "searched_docs = db.similarity_search(query)\n",
    "\n",
    "print(searched_docs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31c87f-0a4a-4db5-bda8-405570ad21fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  another way of doing as above\n",
    "retriever = db.as_retriever()\n",
    "seach_doc = retriever.invoke(query)\n",
    "\n",
    "seach_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478f2ba-09f1-497b-ae5c-51e6ba68e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_n_score = db.similarity_search_with_score(query)\n",
    "\n",
    "docs_n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd725df7-f99d-4e8f-9e3d-805f79860518",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3a75d-5dc1-4d05-a554-460c6da5b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"faiss_index\",embeddings, allow_dangerous_deserialization = True)\n",
    "\n",
    "doc = new_db.similarity_search(query)\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ba037-bf0f-4204-9bba-83e7ac86f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7e2e5-e438-4810-88ff-cc67a4f97138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7213e14e-58b8-45de-82f5-ba3f2f52fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305adf4-c901-461b-b51a-2bc3fd3c260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(docs,embedding,persist_directory = './chroma_db')\n",
    "\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c79219-ba58-419f-9e79-7aaa896b2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who invented langchain?\"\n",
    "searched_docs = vectordb.similarity_search(query)\n",
    "\n",
    "print(searched_docs[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c6fb9-f9e9-41c1-8849-d556aec86887",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = Chroma(persist_directory = \"./chroma_db\",embedding_function = embedding)\n",
    "docs2 = db2.similarty_search(quey)\n",
    "docs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc675085-0bd7-404f-94ee-22059107fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  another way of doing as above\n",
    "retriever = db2.as_retriever()\n",
    "seach_doc = retriever.invoke(query)\n",
    "\n",
    "seach_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9158df-db01-487f-8f5b-69db01ceb412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf63cf2-754e-4ed5-a6fb-9c3afd03ad0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310_env)",
   "language": "python",
   "name": "py310_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
